[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R语言空间数据分析入门教程",
    "section": "",
    "text": "前言\n本书主要介绍使用 R 语言进行空间数据分析的基本方法，共涉及读写、处理、可视化和分析等模块。 主要涉及以下几个包的使用\n\nbase\nrgdal\nggplot\ntmap\nspdep\nGWmodel\n\n随着 R 语言的发展，有些包（如 rgdal）即将退出历史舞台，有些新的包已经提供了更为强大的功能。 但是 R 语言本身的依然没有发生颠覆性改变，本书中介绍的大部分内容依然适用。 希望读者主要领会 R 语言使用的习惯和精神，理解 R 语言设计的思想和哲学。 这样，如果有哪些部分已经不再适用于如今的 R 环境，读者也可以自行搜索更新的资料自行学习。 如果有时间，笔者也会逐步更新本书内容，以求能够赶上当今 R 语言发展的步伐。\n本书所有使用到的数据可以从这里获取\n2023年06月28日  于 Bristol"
  },
  {
    "objectID": "01-数据读写.html#前言数据类型文件格式扩展名之间的关系",
    "href": "01-数据读写.html#前言数据类型文件格式扩展名之间的关系",
    "title": "1  数据读写",
    "section": "1.1 前言：数据类型、文件格式、扩展名之间的关系",
    "text": "1.1 前言：数据类型、文件格式、扩展名之间的关系\n严格地说，这三者并不是一一对应的。这三者相关的定义可以有很多，但是在本教程中，约定：\n\n数据类型指数据存在的形式。如整型是数据以整数的形式存在、向量是指数据以向量的形式存在、表指数据以行列的形式存在等。这个类型并不局限于 R 语言的类型，而是一种抽象的、语言无关的数据组织形式。\n文件格式是指某种数据类型在一个文件中的组织形式。如“逗号分隔值”格式是表格数据在文件中以逗号分隔文本文件的组织形式，相应的也会有 Excel 表格的格式、关系数据库中文件的格式。\n扩展名是指文件名最后一个 . 符号后的字符串，一般用于让计算机系统便于选择合适的软件打开该文件。例如，使用 Word 软件创建的文档，如果后缀名为 docx ，则系统默认使用 Word 软件打开。但如果后缀名改为 zip ，则系统默认使用解压缩软件打开。\n\n但有时，这三者有一些约定的关系，例如后缀名为 csv 的文件，文件格式是“逗号分隔值”，存储的是表类型的数据。 当说到 csv 文件时，可以默认是一个表数据。 所以很多时候这三者会被混用，但仍需注意其本身含义并不一样。"
  },
  {
    "objectID": "01-数据读写.html#基础数据读写",
    "href": "01-数据读写.html#基础数据读写",
    "title": "1  数据读写",
    "section": "1.2 基础数据读写",
    "text": "1.2 基础数据读写\n该部分主要讲解分隔符形式存储的数据，以及 R 特有数据格式文件的读写。某种程度上，空间数据也可以使用基础数据的形式进行存储，因此基础数据的读写时非常重要的。\n在对数据读写之前，需要设置工作目录，到 data/ 文件夹所存在的目录。设置方法是使用 setwd() 函数，参数是 data/ 文件夹所存在的目录的路径。\n\n在 R 控制台中，打开 R 控制台的目录，就是 R 的工作目录。 在 RStudio 中，创建并保存 R 脚本文件后，可以使用菜单中 Session -&gt; Set Working Directory -&gt; To Source File Location 来设置当前工作目录。 在 Jupyter 中，打开 ipynb 文件后，工作目录自动处于该文件所在的目录。\n\n\nsetwd(\".\")\n\n\n1.2.1 表数据\n表数据，是一种常见的数据类型，用列表示的一个或更多的数据种类，每行包含一个唯一的数据实体，这些数据是被列定义的种类。 表又称“关系”，列又称“字段”，行又称“记录”。一般情况下，同一列中的数据类型是相同的。 在统计学研究中，行对应了一个样本，列对应了样本中的一个属性。 这种数据类型就可以轻松的描述样本的所有特征。\n由于表示“表”这一数据类型的文件格式非常多，本节主要讲解以分隔符形式存储的表数据，如 CSV 和 TSV 等，这里以 CSV 文件为例。在 R 中，使用 Excel 文件存储的数据也可以进行读取，请自行参考《R语言空间数据处理与分析实践教程》一书。\n逗号分隔值（Comma Seperated Values, CSV）是一个常用的文件格式，以纯文本形式存储表格数据，但该文件格式并没有统一通行的规范。 一般地，该类型的文件一般在第一行记录各列的名字。有的文件也在第一列记录该行的索引，可称该列为“索引列”，索引列一般没有列名。 值得注意的是，严谨的 CSV 文件一般会用到以下四个特殊字符：\n\n分隔符：通常使用 , ，用于分隔不同列的名称和值\n引号：通常使用 \" ，在一对引号中的所有内容都被认为是同一个字段的值，其中的 , 也被认为是字段值的一部分\n注释：通常使用 # ，出现在该符号后面的文字认为是注释，不算在字段值内\n小数点：通常使用 . ，用于分隔数字类型值得整数部分和小数部分\n\n当然，最常见的 CSV 文件一般只使用分隔符，这就会造成一些问题。\n\n\n1.2.2 表数据读取\n在 R 中，对 CSV 文件的读取是通过 read.csv 函数完成的。\n\ndemo.table &lt;- read.csv(file = \"data/LNHP03.csv\", header = TRUE, sep = \",\", quote = \"\\\"\", dec = \".\", comment.char = \"#\")\n\n该语句创建了名为 demo.table 的变量，这个变量中记录了程序读取文件 data/LNHP03.csv 的结果。\n在函数 read.csv 中，包含如下几个参数：\n\n\n\n\n\n\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\nfile\ncharacter\n输入文件路径（相对路径或绝对路径）\n\n\n\nheader\nlogical\n文件中是否包含列名。如果值是 TRUE ，则认为第一行是列名；否则认为表中没有列名，读取后再进行指定。\nTRUE\n\n\nsep\ncharacter\n分隔符\n,\n\n\nquote\ncharacter\n引号\n\"\n\n\ndec\ncharacter\n小数点\n.\n\n\ncomment.char\ncharacter\n注释\n#\n\n\n\n在 R 中，如果一个函数各个参数是按照顺序进行赋值的，就不需要填写参数名。如果不是，则需要指定参数名。\n在 R 中，具有默认值的参数，在调用函数时，可以不传值。 对于该函数而言，除了第一个参数 file 必须指定以外，其余三个参数在使用时可以不进行指定，此时将采用默认值。 只有当文件中所使用的符号与默认值不同时，才需要进行指定。例如\n\ndemo.table &lt;- read.csv(\"data/LNHP03.csv\")\n\n\n1.2.2.1 查看数据\n我们通过以下语句可以输出这个变量前5行的值\n\nhead(demo.table)\n\n在输出的表格中，可以很清楚地看到列名、列类型、行名以及各个样本各个字段的值。 变量 demo.table 的类型，是一种名为 data.frame 的类型， R 语言中使用这种数据类型来表示表格数据。\n我们可以使用以下操作查看这个表格数据的一些信息\n\nnrow(demo.table)  # 行数\nncol(demo.table)  # 列数\ndim(demo.table)   # 各维度的长度\nrownames(demo.table)  # 行名\ncolnames(demo.table)  # 列名\n\n有关 data.frame 类型变量的相关操作，在后续教程中会进行详细的讲解。\n\n\n1.2.2.2 数量类型\n可以看到，不同的列具有不同的数据类型，有的标注的是 chr ，有的标注的是 dbl 或者 int 。而在参数中，我们有一个参数的类型是 logical ，这就是 R 中的四种数量类型：\n\nchr 代表字符串（character），表示文本\ndbl 代表浮点数（numeric），也是 R 中数字字面量的默认类型。该类型有几个特殊取值，Inf 表示无限数，NaN 表示“Note a Number”，可能是由于计算错误导致的。\nint 代表整数\nlogical 该表逻辑值，取值为 TRUE 或 FALSE 或 NA。TRUE 可以简写为 T ，FALSE 可以简写为 F 。\n\n这些数据类型的用法和 Python 、 Java 等高级语言并没有太大区别。如果要查看某个数据的类型，可以使用 class 函数，例如\n\nclass(1)\nclass(1.0)\nclass(\"1\")\n\n这些数据类型可以进行转换，使用如下一些“as 族”函数：\n\nas.character\nas.numeric\nas.integer\n…\n\n类似于其他编程语言中的强制类型转换。注意 as.integer 不是四舍五入，而是下取整。\n\nas.character(1.5)\nas.numeric(\"1.5\")\nas.integer(1.5)\n\n标量类型可以使用常用的运算符，如 + - * / ，%% 表示取模运算， %\\% 表示整除运算，其他一些运算符和别的编程语言没有什么区别。\n\n1+2\n1*2\n1/2\n10 %% 3\n10 %/% 3\n1 &gt; 1\n1 &gt;= 1\nTRUE | FALSE\nTRUE & FALSE\nTRUE || FALSE\nTRUE && FALSE\n\n\n\n1.2.2.3 赋值运算符\n在上述语句中，使用了一个运算符 &lt;- ，该运算符的含义与“深拷贝”比较类似，用于将函数返回值保存到变量中，或者将一个变量复制一份保存到零一个变量中。 在 R 语言中，变量赋值前不需要提前声明，随时使用随时创建，所以 = 和 &lt;- 都可以创建变量。 这两个符号在实际使用起来区别不是很大，这里就不进行区分了，但需要注意官方推荐使用 &lt;- 而不是 = 。\n例如，将 demo.table 复制一份到变量 londonhp 中，则使用如下语句\n\nlondonhp &lt;- demo.table\n\n\n\n\n1.2.3 表数据写入\n有 read.csv 进行读取，相应地就有 write.csv 进行写入。先看示例\n\nwrite.table(x = demo.table, file = \"output-01/demo.table.csv\", append = FALSE, \n            quote = TRUE, sep = \",\", eol = \"\\n\", na = \"NA\", dec = \".\", \n            row.names = FALSE, col.names = TRUE)\n\n除了 sep dec 等参数和 read.csv 的含义相同外，该函数具有其他一些参数：\n\n\n\n\n\n\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\nx\nobject\n要输出到文件中的对象\n\n\n\nfile\ncharacter\n输出文件路径（相对路径或绝对路径）\n\n\n\nappend\nlogical\n是否追加到输出文件中。如果值是 TRUE ，则在已有文件后面继续添加数据；否则重新创建文件。\nFALSE\n\n\nquote\nlogical/vector(numeric)\n是否将值使用引号引起来，或指定哪几列的值应当使用引号引起来\nTRUE\n\n\nsep\ncharacter\n分隔符\n\\n\n\n\neol\ncharacter\n如果某一行某一列的值是 NA，则用什么字符表示\n\"NA\"\n\n\nrow.names\nlogical/vector(character)\n是否输出行名，或输出什么行名\nTRUE\n\n\ncol.names\nlogical/vector(character)\n是否输出列名，或输出什么列名\nTRUE\n\n\n\n\n1.2.3.1 向量\n值得注意的是，有三个参数可以接收多种类型，而可选的参数类型，都是 vector 类型。该类型是 R 中非常重要的数据类型之一：向量。\n向量是一系列数量的一维数组，一般情况下，这些数量具有相同的类型。在 R 中，向量都是列向量。\n创建向量的方法有很多，例如\n\nc(1,2,3,4)  # 将一组值组合到一个向量中\nc(1:4)\nnumeric(10)  # 创建 10 个元素的 numeric 类型的向量，默认值全为 0\nc(\"x\", \"y\")\ncharacter(4)  # 创建 4 个元素的 character 类型的向量，默认值全为空字符串\n\n二元运算符 : 表示生成一个向量，向量以第一个操作数作为第一个元素，以后每个元素比前一个元素增 1，并且小于第二个操作数。 所以一般用于生成一个整数序列，为了体现这个特点，本教程称以这种方式生成的向量为“序列”\n\n1.1:4.0\n\n如果要取某一个向量中的第 \\(i\\) 个元素，直接使用 变量名[索引] 即可，注意这里的 索引 是从 1 开始计算的，可以是整数、序列、整数类型的向量、逻辑类型的向量。\n\ndemo.vector.numeric &lt;- c(1:10)\ndemo.vector.numeric\ndemo.vector.numeric[1]\ndemo.vector.numeric[5:6]\ndemo.vector.numeric[c(F, T, T, F, F, T, T, F, F, T)]\n\n其中，整数、整数类型的向量中的元素可以是正整数也可以是负整数，如果是负整数，则表示“出去该元素以外的元素”\n\ndemo.vector.numeric[-c(1:2)]\n\n如果要判断一个值或一组值是否在向量中，使用 %in% 运算符，根据返回的 TRUE 或 FALSE 判断。\n\n1 %in% demo.vector.numeric\nc(1,5,20) %in% demo.vector.numeric\n\n向量可以与向量或者数量进行数量运算或逻辑运算。 当向量与数量进行数量运算时，是向量的每个元素与该数量进行运算。 向量与向量进行数量运算时，是两个向量对应位置的元素进行运算，这两个向量不一定要等长，但最好长向量的长度是短向量的长度的整数倍。\n\nc(1:5) + 1\nc(1:5) - 1\nc(1:5) * 2\nc(1:5) ^ 2\nc(1:5) / 10\nc(1:5) %% 10\nc(1:5) %/% 10\nc(1:5) &gt; 2\nc(1:5) &lt; 2\nc(1:5) &gt;= 2\nc(1:5) &lt;= 2\nc(1:5) == 2\nc(1:5) + c(1:10)\nc(1:5) * c(1:10)\n\n向量中元素的类型可以整体进行转换，还是使用“as 族”函数\n\nas.character(c(1:5))\nas.integer(c(1.1:4.0))\nas.numeric(c(\"1.0\", \"1.3\", \"1.5\"))\n\n当向量与数量或向量进行逻辑运算时，运算方法和数量运算还是一样的，但是此时 | & 两个运算符和 || && 两个运算符会产生不一样的结果。\n\nc(TRUE, TRUE, FALSE, FALSE) | c(TRUE, FALSE, TRUE, FALSE)\nc(TRUE, TRUE, FALSE, FALSE) || c(TRUE, FALSE, TRUE, FALSE)\nc(TRUE, TRUE, FALSE, FALSE) || c(FALSE, FALSE, TRUE, FALSE)\nc(FALSE, TRUE, FALSE, FALSE) || c(FALSE, FALSE, TRUE, FALSE)\nc(TRUE, TRUE, FALSE, FALSE) & c(TRUE, FALSE, TRUE, FALSE)\nc(TRUE, TRUE, FALSE, FALSE) && c(TRUE, FALSE, TRUE, FALSE)\nc(TRUE, TRUE, FALSE, FALSE) && c(FALSE, FALSE, TRUE, FALSE)\n\n可见，使用 | & 会生成一个结果向量，各个元素是两个变量中各个元素对应运算的结果。而 || && 只是两个向量第一个元素运算的结果。\n\n\n\n1.2.4 R 语言二进制数据文件\n这是一种 R 语言特有的数据文件，基本相当于以二进制的方式将数据直接存储到文件中，使用时可以直接加载到内存，节省了读取、解析数据的时间。 这种文件常用 rds 或 rda 作为扩展名。\n如果我想将当前的 demo.table 和 londonhp 同时保存到一个 rds 文件中，则可使用如下两种方式\n\nsave(demo.table, londonhp, file = \"output-01/demo1.rds\")\nsave(list = c(\"demo.table\", \"londonhp\"), file = \"output-01/demo2.rds\")\n\n该函数具有如下参数\n\n\n\n\n\n\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\n...\nobject\n要输出到文件中的变量。这是一个变长参数，可以接收任意个参数。\n\n\n\nlist\nvector(character)\n要输出到文件中的变量的名称\n\n\n\nfile\ncharacter\n输出文件路径（相对路径或绝对路径）\n\n\n\n\n需要注意的是，该函数具有变长参数，所以只要参数没有指定参数名，都被认为是这个参数的值。 因此，当需要给参数 list 或者 file 传值时，就必须指定该参数的名称，软件才能正确地把参数值传递到对应的参数中。\n如果要加载之前保存的变量，就可以使用 load() 函数\n\nload(\"output-01/demo1.rds\")\n\n这样，output-01/demo2.rds 文件中所保存的变量，就被加载到当前工作空间中。\n\n工作空间是一个非常复杂的问题，这里暂不展开讨论。需要注意的是，R 语言在运行时，会开启一个 R 控制台，又称“节点”，在 RStudio 中又称 Terminal，在 Jupyter Notebook 中又称 Kernel 。 这个节点只要不关闭，就一直保存着所有创建的变量。这些变量所在的地方，就是一个工作空间。\n\n如果想要验证数据是否被加载，此时重启 R 进程（Terminal, Kernel），然后再重新运行如下语句\n\nload(\"output-01/demo2.rds\")  # 或者 load(\"output-01/demo2.rds\")\nhead(londonhp)\n\n数据可以被正确加载。可以看到，这样加载数据的方式，比 read.csv 的方式要快，因此推荐比较大的数据可以在使用 read.csv 读取后，保存为 rds 文件。\nR 本身还有一些软件包自带了一些数据，例如 iris 数据集。可以使用 data() 函数进行加载\n\ndata(iris)\nhead(iris)\n\n\n以上数据中出现的 fct 类型也是一种数量类型，指 factor 类型，即“因子”。这里暂不展开讨论。"
  },
  {
    "objectID": "01-数据读写.html#空间数据的读写",
    "href": "01-数据读写.html#空间数据的读写",
    "title": "1  数据读写",
    "section": "1.3 空间数据的读写",
    "text": "1.3 空间数据的读写\n空间数据读写主要指使用 ESRI Shapefile 格式存储的数据（不包含栅格数据）。 存储空间数据的文件格式有很多，除了 ESRI Shapeifle 以外，常用的还有 GeoJSON 、 Geography Markup Language 等，一些数据库也支持存储空间数据。 但仍属 ESRI Shapeifle 最为常用，几乎所有的空间数据分析软件（如 ArcGIS、GeoDa 等）都支持该文件格式。\n\n1.3.1 ESRI Shapefile 文件空间数据的读取\n有关 ESRI Shapefile 文件格式，需要注意以下几点：\n\n该格式需要使用多个文件存储空间数据，一般有如下几个后缀的文件： shp shx dbf prj sbn sbx 。\n该格式限制列名不能超过 10 个字符，如果超出这个长度，列明会被截断\nESRI Shapefile 格式可以存储空间点、线、面数据，读取的方法类似，只是在使用时会有一些不同。这些不同将在后续教程中详细指出。\n\n如果要读取一个 ESRI Shapefile 文件，需要使用 rgdal ，如果没有安装过这个包，则使用函数 install.packages(rgdal) 进行安装，参数是包的名字。\n\n1.3.1.1 空间点数据\n使用 rgdal 包中的 readOGR() 函数读取一个空间点数据\n\ndemo.point &lt;- rgdal::readOGR(\"data/LNHP03.shp\")\n\n如果经常使用 rgdal 包中的函数，可以先使用 library() 函数将包进行加载，然后直接使用 readOGR() 函数读取数据。\n\nlibrary(rgdal)\ndemo.point &lt;- readOGR(\"data/LNHP03.shp\")\n\nreadOGR() 函数的参数其实有很多，但是如果读取 ESRI Shapefile 文件的话，一般只需要这一个参数即可。所以关于其他参数，这里就不展开讲解了。\n可以输出一下 demo.point 变量的值，来查看该数据的详情\n\ndemo.point\n\n该数据也类似于一个表数据，但是之前多了一列 coordinates。 实际上，该变量的类型是 SpatialPointDataFrame ，类似于一种自定义的结构体（在 R 中被称作 S4-Class），一般具有以下几个“插槽”（类似于结构体中的属性）\n\n@bbox 表示数据的包围盒\n@proj4string 表示数据的坐标系\n@coords 表示每个要素的坐标\n@data 表示每个要素对应的属性值\n\n和结构体类似，每个插槽也有不同的数据类型。通过如下方式获取这些插槽的值\n\ndemo.point@bbox\ndemo.point@proj4string\nhead(demo.point@coords)\nhead(demo.point@data)\n\n\n这里的 @ 也是一个 R 语言的运算符，类似于其他面向对象语言中的 . ，用于获取类对象的属性值。具体作用不做展开。\n\n\n\n1.3.1.2 矩阵\n注意 @bbox 插槽的值，和 @coords 插槽的值\n\ndemo.point@bbox\n\n可以看到，该插槽值的类型是 matrix ，这是 R 中非常重要的数据类型之一：矩阵。 矩阵是一系列数量的二维数组，一般情况下，这些数量具有相同的类型。\n矩阵的创建一般是通过 matrix() 函数进行的，该函数指明了矩阵中的数据、行数、列数等信息，以及数据是按照行优先还是列优先的方式给出的。\n\ndemo.matrix.numeric &lt;- matrix(data = c(1:12), nrow = 3, ncol = 4, byrow = FALSE)\ndemo.matrix.numeric\n\n该函数具有如下参数\n\n\n\n\n\n\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\ndata\nnumeric/charactor/vector\n矩阵的数据。如果传入的是数量，则所有元素初始化为该值。如果传入的是向量，则按照 byrow 指定的顺序填入矩阵各个元素中。\nNA\n\n\nnrow\nnumeric\n行数\n1\n\n\nncol\nnumeric\n列数\n1\n\n\nbyrow\nlogical\n元素赋值的顺序。如果为 TRUE 则数据一行一行地填入；否则，数据将一列一列地填入。\nFALSE\n\n\n\n可以通过运算符 [] 获取矩阵中一个区域的值，使用方法是 变量名[行号,列号] ，这里的行号和列号可以是整数、序列、整型向量、逻辑型向量，还可以不填（表示所有），可以实是正整数也可以是负整数。\n\ndemo.matrix.numeric[1:2, ]  # 取 1、2 行\ndemo.matrix.numeric[, 1:2]  # 取 1、2 列\ndemo.matrix.numeric[1, 2]   # 取第 1 行第 2 个元素\ndemo.matrix.numeric[1, -2]  # 取第 1 行除第 2 个元素以外的元素\ndemo.matrix.numeric[c(1:3) &gt; 1, ]  # 取第 2 行之后的所有行\n\n可以使用 %in% 运算符判断元素在不在矩阵中\n\n1:2 %in% demo.matrix.numeric\n\n矩阵可以使用 + - * / 四个运算符，这时两个矩阵必须形状一样，进行元素对应运算。 矩阵乘法使用的 %*% 运算符，例如\n\nmatrix(1:3, nrow = 3) %*% matrix(1:5, ncol = 5)\n\n运算符 %*% 也可以用于向量和矩阵。因此上面这条语句相当于\n\nc(1:3) %*% t(c(1:5))\n\n这里面使用了一个函数 t() 表示转置，向量经过转置后，就形成了 matrix 类型。 这个函数可以转置很多类型的变量，包括 vector, matrix, 以及 data.frame 类型。\n矩阵也是可以有行名和列名的，虽然一般不用，但是在将矩阵转换为 data.frame 时会用到。可以通过如下方式设置列名和行名，但可以不必同时设置\n\nrownames(demo.matrix.numeric) &lt;- c(\"r1\", \"r2\", \"r3\")\ncolnames(demo.matrix.numeric) &lt;- c(\"c1\", \"c2\", \"c3\", \"c4\")\ndemo.matrix.numeric\n\n矩阵同样可以使用“as族”函数进行数据类型转换。此外，还可以使用 as.data.frame() 函数将矩阵转换为 data.frame ，例如\n\nas.data.frame(demo.matrix.numeric)\n\n\n\n\n1.3.2 将表数据转换为空间数据\n有些情况下，CSV 文件也被用来存储空间数据，一般是空间点数据。我们可以通过一些方法，将这种表数据转换成空间点数据。 这里需要用到函数包 sp 中的 coordinates() 和 proj4string() 两个函数。\n\nlibrary(sp)\ndemo.csv.point &lt;- read.csv(\"data/WHSHP.csv\")\ncoordinates(demo.csv.point) &lt;- ~ lon + lat  # 设置坐标所存在的列\nproj4string(demo.csv.point) &lt;- \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"  # 设置空间参考\nclass(demo.csv.point)\n\n这里使用到了一个 ~ 多元运算符，该运算符的作用是生成一个 formula 类型的变量。 从名字可以看出来，这个类型的变量表示一个数学公式， ~ 两边可以有不定数量的字段名，不同函数对这一类型变量在 ~ 两边的字段名数量不同。 对于 coordinates() 函数，接收右边有两个字段名的变量，这两个变量分别表示 \\(x\\) 和 \\(y\\) 坐标。\nproj4string() 函数接收一个 Proj4 格式的字符串，不同坐标系的字符串表示方法不同，可以在 SpatialReference 网站上查到。\n\n\n1.3.3 将空间数据输出到文件中\n既然有 readOGR() 函数，相应的就有 writeOGR() 函数，该函数可以将 Spatial*DataFrame 类型的变量输出到 ESRI Shapefile 格式的文件中。\n\nwriteOGR(demo.csv.point, \"output-01/WHSHP.shp\", layer = \"WHSHP\", driver = \"ESRI Shapefile\")\n\n该函数具有如下参数：\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\nobj\nSpatial*DataFrame\n要输出到文件中的变量。\n\n\n\ndsn\ncharacter\n输出文件的路径\n\n\n\nlayer\ncharacter\n输出图层的名称\n\n\n\ndriver\ncharacter\n输出文件的格式，不是扩展名。\n\n\n\noverwrite_layer\nlogical\n是否覆盖图层\nFALSE\n\n\n\n上述命令在重复执行时，会报错，原因是参数 overwrite_layer 默认值是 FALSE ，导致函数默认以追加的方式写入。 如果输出文件已经存在，则需要将 overwrite_layer 参数指定为 TRUE 。"
  },
  {
    "objectID": "01-数据读写.html#附注rgdal-支持的格式",
    "href": "01-数据读写.html#附注rgdal-支持的格式",
    "title": "1  数据读写",
    "section": "1.4 附注：rgdal 支持的格式",
    "text": "1.4 附注：rgdal 支持的格式\nreadOGR() 和 writeOGR() 支持相当多的格式\n\nPCIDSK -raster,vector- (rw+v): PCIDSK Database File\nnetCDF -raster,multidimensional raster,vector- (rw+s): Network Common Data Format\nPDS4 -raster,vector- (rw+vs): NASA Planetary Data System 4\nVICAR -raster,vector- (rw+v): MIPL VICAR file\nJP2OpenJPEG -raster,vector- (rwv): JPEG-2000 driver based on OpenJPEG library\nPDF -raster,vector- (rw+vs): Geospatial PDF\nMBTiles -raster,vector- (rw+v): MBTiles\nEEDA -vector- (ro): Earth Engine Data API\nDB2ODBC -raster,vector- (rw+): IBM DB2 Spatial Database\nESRI Shapefile -vector- (rw+v): ESRI Shapefile\nMapInfo File -vector- (rw+v): MapInfo File\nUK .NTF -vector- (rov): UK .NTF\nOGR_SDTS -vector- (rov): SDTS\nS57 -vector- (rw+v): IHO S-57 (ENC)\nDGN -vector- (rw+v): Microstation DGN\nOGR_VRT -vector- (rov): VRT - Virtual Datasource\nREC -vector- (ro): EPIInfo .REC\nMemory -vector- (rw+): Memory\nBNA -vector- (rw+v): Atlas BNA\nCSV -vector- (rw+v): Comma Separated Value (.csv)\nNAS -vector- (rov): NAS - ALKIS\nGML -vector- (rw+v): Geography Markup Language (GML)\nGPX -vector- (rw+v): GPX\nKML -vector- (rw+v): Keyhole Markup Language (KML)\nGeoJSON -vector- (rw+v): GeoJSON\nGeoJSONSeq -vector- (rw+v): GeoJSON Sequence\nESRIJSON -vector- (rov): ESRIJSON\nTopoJSON -vector- (rov): TopoJSON\nOGR_GMT -vector- (rw+v): GMT ASCII Vectors (.gmt)\nGPKG -raster,vector- (rw+vs): GeoPackage\nSQLite -vector- (rw+v): SQLite / Spatialite\nODBC -vector- (rw+): ODBC\nWAsP -vector- (rw+v): WAsP .map format\nPGeo -vector- (ro): ESRI Personal GeoDatabase\nMSSQLSpatial -vector- (rw+): Microsoft SQL Server Spatial Database\nPostgreSQL -vector- (rw+): PostgreSQL/PostGIS\nOpenFileGDB -vector- (rov): ESRI FileGDB\nXPlane -vector- (rov): X-Plane/Flightgear aeronautical data\nDXF -vector- (rw+v): AutoCAD DXF\nCAD -raster,vector- (rovs): AutoCAD Driver\nFlatGeobuf -vector- (rw+v): FlatGeobuf\nGeoconcept -vector- (rw+v): Geoconcept\nGeoRSS -vector- (rw+v): GeoRSS\nGPSTrackMaker -vector- (rw+v): GPSTrackMaker\nVFK -vector- (ro): Czech Cadastral Exchange Data Format\nPGDUMP -vector- (w+v): PostgreSQL SQL dump\nOSM -vector- (rov): OpenStreetMap XML and PBF\nGPSBabel -vector- (rw+): GPSBabel\nSUA -vector- (rov): Tim Newport-Peace’s Special Use Airspace Format\nOpenAir -vector- (rov): OpenAir\nOGR_PDS -vector- (rov): Planetary Data Systems TABLE\nWFS -vector- (rov): OGC WFS (Web Feature Service)\nOAPIF -vector- (ro): OGC API - Features\nHTF -vector- (rov): Hydrographic Transfer Vector\nAeronavFAA -vector- (rov): Aeronav FAA\nGeomedia -vector- (ro): Geomedia .mdb\nEDIGEO -vector- (rov): French EDIGEO exchange format\nSVG -vector- (rov): Scalable Vector Graphics\nCouchDB -vector- (rw+): CouchDB / GeoCouch\nCloudant -vector- (rw+): Cloudant / CouchDB\nIdrisi -vector- (rov): Idrisi Vector (.vct)\nARCGEN -vector- (rov): Arc/Info Generate\nSEGUKOOA -vector- (rov): SEG-P1 / UKOOA P1/90\nSEGY -vector- (rov): SEG-Y\nXLS -vector- (ro): MS Excel format\nODS -vector- (rw+v): Open Document/ LibreOffice / OpenOffice Spreadsheet\nXLSX -vector- (rw+v): MS Office Open XML spreadsheet\nElasticsearch -vector- (rw+): Elastic Search\nWalk -vector- (ro): Walk\nCarto -vector- (rw+): Carto\nAmigoCloud -vector- (rw+): AmigoCloud\nSXF -vector- (rov): Storage and eXchange Format\nSelafin -vector- (rw+v): Selafin\nJML -vector- (rw+v): OpenJUMP JML\nPLSCENES -raster,vector- (ro): Planet Labs Scenes API\nCSW -vector- (ro): OGC CSW (Catalog Service for the Web)\nVDV -vector- (rw+v): VDV-451/VDV-452/INTREST Data Format\nGMLAS -vector- (rwv): Geography Markup Language (GML) driven by application schemas\nMVT -vector- (rw+v): Mapbox Vector Tiles\nNGW -raster,vector- (rw+s): NextGIS Web\nMapML -vector- (rw+v): MapML\nTIGER -vector- (rw+v): U.S. Census TIGER/Line\nAVCBin -vector- (rov): Arc/Info Binary Coverage\nAVCE00 -vector- (rov): Arc/Info E00 (ASCII) Coverage\nHTTP -raster,vector- (ro): HTTP Fetching Wrapper\n\n因此，有时 ESRI Shapefile 并不一定是最好的选择，尤其考虑到其字段名不能超过 10 个字符的限制。"
  },
  {
    "objectID": "02-数据预处理.html#单个表数据的操作",
    "href": "02-数据预处理.html#单个表数据的操作",
    "title": "2  数据预处理",
    "section": "2.1 单个表数据的操作",
    "text": "2.1 单个表数据的操作\n上节已经讲到，用列表示的一个或更多的数据种类，每行包含一个唯一的数据实体。 因此，对表数据的操作将从行、列两个角度进行展开。 我们将单个表数据的操作归为“创建、增加、查询、修改、删除”五个类型。\n\n2.1.1 创建\n创建一个表，是使用 data.frame() 函数进行的。创建表时，需要指定这个表里面有哪些列，每一列有哪些数据。例如我们使用如下语句创建一个表\n\ndemo.suspect &lt;- data.frame(\n    name = c(\"张三\", \"李四\", \"王五\"),\n    age = c(20, 26, 30),\n    gender = c(\"M\", \"F\", \"M\"),\n    height = c(1.78, 1.65, 1.70),\n    weight = c(80, 45, 60),\n    shoe.size = c(43,38,41)\n)\ndemo.suspect\n\n函数 data.frame() 具有如下参数：\n\n\n\n\n\n\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\n...\n变长参数\n每一列的值。可以指定参数名，也可以不指定。如果指定参数名，则使用参数名作为列名。\n\n\n\nrow.names\ninteger/character/vector(integer/character)\n指定行名\nNULL\n\n\ncheck.rows\nlogical\n检查列名是否符合语法、是否存在重复等问题\nFALSE\n\n\n\n需要指出的是：\n\n每列的值不一定要是向量；如果是向量，则各列值一定要一样长。\n可以不指定任何列，以创建一个空表。但建议提前创建好表结构，以提高程序运行速度。\n\n\ndata.frame(\n    name = c(\"张三\", \"李四\", \"王五\"),\n    age = c(20, 26, 3),\n    gender = \"M\"\n)\n\n\ndata.frame()  # 空表数据\n\n\n\n2.1.2 查询\n查询一行或者一列，可以使用与查看矩阵相同的方法，即使用 [] 运算符。 可以像矩阵一样，在 [] 中使用整数、序列、整型向量、逻辑型向量或者省略行列索引其中之一来获取数据。\n\ndemo.suspect[c(1,2), c(2,3)]\n\n对于具有列名或行名的矩阵或表数据，可以通过指定其行名、列名来获取数据\n\ndemo.suspect[, c(\"name\", \"height\", \"weight\")]\n\n如果只取某一列的所有值，可以使用运算符 $ 获取这一列的值，例如\n\ndemo.suspect$gender\n\n还可以使用运算符 [[ ]]，中间既可以填写列索引，也可以填写列名，例如\n\ndemo.suspect[[\"gender\"]]\ndemo.suspect[[3]]\n\n以上只是对数据简单的查找。能否像数据库一样，给数据中指定一些条件，筛选出符合条件的数据呢？答案是可以的，而且有多种方式可以做到。这里介绍三种。\n第一种是直接使用逻辑判断表达式，得到一组逻辑类型的向量，根据该向量获取对应位置上的元素。例如提取 demo.suspect 中 gender 列为 M 的行，可以这样操作\n\ndemo.suspect[demo.suspect$gender == 'M',]\n\n第二种是稍微有些多此一举，使用 which() 函数。这个函数接收一个逻辑类型的向量作为参数（如果不是向量，也会被转换成向量），返回这些向量中值为 TRUE 的元素的位置。例如\n\nwhich(demo.suspect$gender == 'M')\ndemo.suspect[which(demo.suspect$gender == 'M'),]\n\n第三种是使用一个强大的 dplyr 包，该包提供了 select 和 filter 两个函数，可以大大简化对数据的查找。 其中，select 函数偏向于获取列，filter 函数偏向于获取行，基本对应了 SQL 语句中 select 和 where 两个子句，但提供了更多的功能。\n以下是一些 select 函数的示例\n\nselect(demo.suspect, name)  # 获取 name 列\n\n\nselect(demo.suspect, c(\"height\", \"weight\", \"shoe.size\"))\n\n\nselect(demo.suspect, height:shoe.size)  # 获取 height 到 shoe.size 等列\n\n\nselect(demo.suspect, ends_with(\"ght\"))  # 获取以 \"ght\" 结尾的列\n\n\nstarts_with 和 ends_with 是 dplyr 提供的判断字符串开头和结尾的两个函数，\n\n可以看到，该函数可以接收多种类型的参数：字符串、字符串向量、:表示的序列，以及一些函数返回值。\n以下是一些 filter 函数的使用示例\n\nfilter(demo.suspect, name == \"张三\")\n\n\nfilter(demo.suspect, gender == \"M\" & age &gt; 20)\n\n\nfilter(demo.suspect, gender == \"M\", age &gt; 20)\n\n\nfilter(demo.suspect, between(age, 20, 30))\n\n\nfilter(demo.suspect, gender == \"M\", ((height * 100 - 80) * 0.7) &lt; weight)\n\n可见，该函数还是主要接收一个逻辑类型的向量作为筛选依据，可以看作是对第一种数据检索方式的简化。 该函数也可以接收多个条件，多个条件之间是使用 & 运算符连接的。 该函数还可以在列之间进行比较，也可以对列做一些运算后比较。 该函数还支持一些函数，用于方便进行数据检索：\n\nbetween(x, L, U) 判断变量 \\(x\\) 的元素是否落在 \\([L,U]\\) 的区间内\nnear(x, c) 对于浮点数 \\(x\\) 来说，直接使用 x == c 来判断 \\(x\\) 和 \\(c\\) 是否相等，会存在一些问题。该函数是用来判断 \\(x\\) 和 \\(c\\) 是否在浮点误差内相等。\nis.na(x) 判断变量 \\(x\\) 是否是 NA\n\n当然这两个函数可以进行嵌套\n\nselect(filter(demo.suspect, shoe.size &lt; 42), \"name\":\"gender\")\n\n\n\n2.1.3 分组查询\n在 R 语言中，还可以对数据进行分组查询，相当于 SQL 中的 group by 子句。实现这一操作有几种方式。\n一种是使用 dplyr 包中提供的 group_by() 函数，该函数给数据指定一个分组依据，但不对数据进行分组处理。使用 summarise() 或 summarize() 函数进行分组处理。 使用一次 group_by() 函数，数据中增加一层分组条件；使用一次 summarise() 函数，数据中减少一次分组条件。\n\nsummarise(group_by(demo.suspect, gender), height.mean = mean(height), weight.mean = mean(weight), married.num = length(which(is.married)))\n\n\n这里用到了 mean() 和 length() 两个函数，其作用分别是计算平均数和向量长度。\n\n这种方式就非常类似于 SQL 语句的方式，使用起来也非常方便。\n另一种是使用 R 自带的 aggregate 函数，对数据进行聚合。例如\n\naggregate(demo.suspect[, c(\"height\", \"weight\", \"shoe.size\", \"BMI\")], by = list(demo.suspect$gender), FUN = mean)\n\n该函数具有如下参数：\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\nx\ndata.frame\n要处理的数据\n\n\n\nby\nlist\n分组依据\n\n\n\nFUN\nfunction\n聚合函数。将每一列传入到函数的第一个参数中。\n\n\n\n...\nlogical\n聚合函数的额外参数\n\n\n\n\n这里涉及到两个类型 list 和 function ，即列表类型和函数类型。\n\n2.1.3.1 列表类型\n列表类型，有点类似于其他编程语言的字典类型（C++ 中对应 Map 类型），是以键值对方式存在的数据。 其中值必须有，但键名不一定必须有。当键名有时，可以比较类似于字典；当键名没有时，比较类似于任意列表。 因此该类型的使用非常灵活，可以和 JSON 数据对应。\n创建列表类型变量的方式和创建表数据的方式很像，使用如下方式\n\nlist(\n    name = \"张三\", gender = \"Male\", age = 30, \n    children = list(\n        list(name = \"张军\", gender = \"Male\", age = 3),\n        list(name = \"张灵\", gender = \"Female\", age = 2)\n    ),\n    interests = c(\"体育\", \"音乐\")\n)\n\n事实上，data.frame 类型只是一个特殊的 list 类型，特殊在不同键的值具有相同的长度。\n在 aggregrate 函数中，如果 by 参数传入的列表只有几个键值对，那么就按照这几个条件进行分组。多个条件分组的示例如下\n\naggregate(demo.suspect[, c(\"height\", \"weight\", \"shoe.size\", \"BMI\")], by = list(demo.suspect$gender, demo.suspect$is.married), FUN = mean)\n\n\n\n2.1.3.2 函数类型\nR 中，函数也是一个变量，即函数类型的变量（有点 JavaScript 那味了），但是 () 运算符只能作用于函数类型的变量上。\n创建函数类型的变量使用 function 关键字，将最后一条运行的语句的结果作为返回值。例如，创建一个计算二次函数值的变量\n\nquadratic &lt;- function(x, a = 1, b = 0, c = 0) {\n    (a * x^2 + b * x + c)\n}\nquadratic(1)\nquadratic(1, 1, 2)\nquadratic(1, 1, 2, 1)\n\nR 语言中的函数无需使用 return 指明返回值， return() 也是一个函数，但其只起到控制函数流程的作用。\nR 语言中也提供了丰富的函数，用于进行简单的统计计算，包括 mean(), sd(), var(), min(), max(), median(), length(), range(), quantile(), fivenum() 等。 这些函数可以直接使用。\n\nmean(1:5)       # 平均数\nsd(1:5)         # 标准差\nvar(1:5)        # 方差\nmin(1:5)        # 最小值\nmax(1:5)        # 最大值\nmedian(1:5)     # 中位数\nlength(1:5)     # 长度\nrange(1:5)      # 极值\nquantile(1:10)  # 四分位数\nfivenum(1:10)   # 四分位数（与上一种算法不同）\n\n\n\n2.1.3.3 判断语句\n在之前可以看到，我们调用 mean 作为统计函数的时候，如果遇到字符串或逻辑值，其统计结果是有问题的。这时就需要我们使用自定义的函数，对不同类类型的列进行处理\n\naggregate(demo.suspect, by = list(demo.suspect$gender), FUN = function(x) {\n    if (class(x) == \"character\") {\n        length(x)\n    } else if (class(x) == \"logical\") {\n        length(which(x))\n    } else {\n        mean(x)\n    }\n})\n\n这里使用到了 if else 关键字进行函数流程的控制。 if 关键字后面使用 () 包含一个逻辑表达式表示条件，当该条件成立时执行 {} 中的语句；不成立时，如果有 else 则执行 else 后 {} 的语句。\n\n\n2.1.3.4 循环语句\n。 与其它语言类似，R 语言中也有 for while 两种循环语句。这里顺便介绍一下。\nfor 语句的用法是\n\nfor (i in demo.suspect$height) {\n    print(i * 100)\n}\n\n\n这里的 print() 函数将变量进行输出。\n\nwhile 语句的用法是\n\ni &lt;- 2\nwhile (i &gt; 0.0001) {\n    i &lt;- i / 2\n}\ni\n\n需要指出的是，R 语言执行 for while 循环的效率比较低，因此不建议大量使用循环语句，推荐使用向量化计算方法，即将循环对象作为一个向量进行整体计算。 如果一定要对每一个值单独进行处理，在 R 中也有更高效的方法。\n\n\n\n2.1.4 增加\n对数据增加一列，可以使用 $ 运算符或者 [[]] 运算符，只要这一列的名字没有在数据中出现，直接赋值即可。新增的列出现在最后面。例如\n\ndemo.suspect0 &lt;- demo.suspect # 备份一下\n\n\ndemo.suspect$married &lt;- c(T, T, F)\ndemo.suspect\n\n\ndemo.suspect[[\"children.count\"]] &lt;- c(2, 1, 0)\ndemo.suspect\n\n我们也可以将一些计算值加入到列中，例如计算 BMI 指数\n\ndemo.suspect$BMI &lt;- demo.suspect$weight / demo.suspect$height^2\ndemo.suspect\n\n以上这些操作，都可以使用一个函数 transform() 完成，该函数的用法类似于 select filter 两个函数，在后面可以直接指定新列的值\n\ntransform(demo.suspect0, BMI = weight / height^2, married = c(T, T, F), children.count = c(2, 1, 0))\n\n增加列的操作是比较简单的。对于增加行的操作，由于不同列的数据类型不同，因此比较复杂。\n如果有行名，可以使用 [行名,列名] 的方式，指定一个新行名的索引，填入数据即可。 建议分别赋值，可保证列不改变。\n\nrow.names(demo.suspect0) &lt;- demo.suspect0$name\ndemo.suspect0[\"赵六\", \"name\"] &lt;- \"赵六\"\ndemo.suspect0[\"赵六\", \"age\"] &lt;- 29\ndemo.suspect0\n\n如果没有行名，可以使用函数 nrow() 计算以下当前的行数 \\(r\\)，使用 [r+1,列名] 的方式填入数据。\n还可以使用 rbind() 函数增加一行，使用方法如下\n\ndemo.suspect &lt;- rbind(demo.suspect, data.frame(\n    name = \"赵六\",\n    age = 19,\n    gender = \"F\",\n    height = 1.6,\n    weight = 43,\n    shoe.size = 37,\n    BMI = 43 / 1.6^2,\n    married = F,\n    children.count = 0\n))\ndemo.suspect\n\n但该函数效率较低，应尽量避免使用。同样地，R 中也有一个 cbind 函数，其用法和 rbind 类似，只是用于增加列，但该函数效率也比较低，因此不推荐使用。\n\n\n2.1.5 修改\n该部分所说的改，包括对名、类型、值的修改。\n修改表数据列名和行名的方法和矩阵是类似的，都是使用 row.names() 和 col.names() 两个函数进行的。值得注意的是，不一定一次要全部修改。例如\n\ncolnames(demo.suspect)[7] &lt;- \"is.married\"\ndemo.suspect\n\n修改类型，特指修改列的类型，方法还是使用 as 族函数，通过对一列进行整体操作，例如\n\ndemo.suspect$age &lt;- as.integer(demo.suspect$age)\ndemo.suspect$children.count &lt;- as.integer(demo.suspect$children.count)\ndemo.suspect\n\n修改值的方法和修改类型的方法基本一样，例如如果给 age 整体增 1，可以使用以下方式\n\ndemo.suspect$age &lt;- demo.suspect$age + 1\ndemo.suspect\n\n当然也可以对某一个值单独进行赋值，例如将 王五 的 is.married 列的值修改为 T\n\ndemo.suspect[demo.suspect$name == \"王五\", \"is.married\"] &lt;- T\ndemo.suspect\n\n与增操作类似，一般不对行进行整体的改操作。\n\n2.1.5.1 删\n删除一行或者一列的方法，等价于选择另外一些行或者列。例如如果要删除 children.count 这一列，或者删除 children.count 这一列的值小于 1 的，只需要选择其他列，即可。 而如果列比较多，要删的列只有一两个，进行查询操作并不是很方便。此时可以使用负整数索引进行删除。例如\n\ndemo.suspect[-c(4),-c(8)]\n\n此外，如果知道列名， transform 函数也可以用于删除列，只需要将该列的值设置为 NULL 即可\n\ntransform(demo.suspect, is.married = NULL)\n\n\n\n\n2.1.6 多个表的操作\n很多时候，不同部分的数据是分别收集的，会形成多个表数据。对于这种情况，在数据处理时，就需要将两张表进行连接。 使用原生 R 的语句可以做到这一点，但是会比较麻烦。这里还是主要介绍 dplyr 包中提供的方法。\n先创建一个新的数据集，使用的数据是 R 中自带的，主要是关于美国各州的一些情况。此外还需要用到一个自带的表数据 USArrests。\n\nstates.info &lt;- data.frame(name = state.name, abb = state.abb, state.center, area = state.area)\nstates.arrests &lt;- USArrests[4:20,]\nstates.arrests$name &lt;- rownames(states.arrests)\nhead(states.info)\nhead(states.arrests)\n\n\n由于 data.frame 是一个特殊的 list，创建 data.frame 时也可以直接传入 list 数据，该 list 中的每一个值的要求，和对其他字段的要求相同。\n\n下面我们需要将这两个表进行关联。如果两个数据是一一对应的，可以直接使用 cbind() 函数。 但这与这种数据，显然不是，就需要使用进行连接操作，使用到的函数主要有四种：\n\ninner_join()：只保留两者完全匹配到的记录\nleft_join()：保留左边所有记录\nright_join()：保留右边所有记录\nfull_join()：保留两边所有记录\n\n这几个函数接受的参数是一样的。\n\ninner_join(states.info, states.arrests, by = c(\"name\"))\n\n\nleft_join(states.info, states.arrests, by = c(\"name\" = \"name\"))\n\n这些函数中，前两个参数显然就是要连接的两张表，第一个参数是左表，第二个参数是右表。参数 by 就是连接条件。 该参数可以有多种形式：\n\n用 c 函数创建一组键值对，键表示第一张表的连接字段，值表示第二张表的连接字段。\n字符串向量，在两张表中找字符串中的字段进行连接。\nNULL ，函数在两张表中寻找同名字段进行连接。\n\n连接后的表包含了两张表的所有字段，如果字段有重名，那么会在字段后面加上后缀，默认是 .x .y ，但是也可以通过 suffix 参数进行控制。这里具体就不再进行演示了。"
  },
  {
    "objectID": "02-数据预处理.html#向量化计算",
    "href": "02-数据预处理.html#向量化计算",
    "title": "2  数据预处理",
    "section": "2.2 向量化计算",
    "text": "2.2 向量化计算\n之前提到，R 语言中执行循环的效率是比较低的，提高效率的方法就是向量化计算，即以向量为单位进行计算。 如果向量之间各元素的操作相同，且比较简单，那么可以直接使用向量运算来进行，这是最为推荐的方式。 但是如果向量计算的操作比较复杂，这时就需要用到 apply 族函数了。这些函数主要包括以下几个：\n\napply 针对矩阵进行计算\nlapply 针对列表进行计算\nsapply 针对列表进行计算，结果会进行自动化简\nvapply 针对向量进行计算，\n…\n\n例如，我们现在有一个 \\(n \\times n\\) 的距离矩阵（这里使用 dist 函数生成，也可以从外部导入），我们需要找到每一列中排名第 20 的距离值。就可以使用 apply 函数进行计算。\n\ndistance.mat &lt;- as.matrix(dist(states.info[, c(\"x\", \"y\")]))\ndim(distance.mat)\napply(X = distance.mat, MARGIN = 2, FUN = function(d) {\n    sort(d)[20]\n})\n\n该函数具有如下参数：\n\n\n\n\n\n\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\nX\nmatrix\n要处理的数据\n\n\n\nMARGIN\ninteger\n处理的维度。取 1 时，表示对每一行进行处理。取 2 时，表示对每一列进行处理。\n\n\n\nFUN\nfunction\n执行函数。根据 MARGIN 将每一行或每一列作为第一个参数传入。\n\n\n\n...\nlogical\n执行函数的额外参数。\n\n\n\n\n函数在返回时，每一次执行函数的结果进行组合。如果执行的结果是数量，则组合成一个向量。如果执行的结果是向量，则作为一列组合成一个矩阵。\n在第一节中，我们读取了一个表数据，但是有些字段应该是浮点数，系统判断成了字符串类型；有些是整数，系统默认为浮点数。 对于这种情况，我们就可以使用 lapply 对其进行转换\n\ndemo.table &lt;- read.csv(\"data/LNHP03.csv\")\ndemo.table[,c(\"X\", \"Y\")] &lt;- lapply(demo.table[,c(\"X\", \"Y\")], as.numeric)\ndemo.table[,c(\"PURCHASE\", \"FLOORSZ\")] &lt;- lapply(demo.table[,c(\"PURCHASE\", \"FLOORSZ\")], as.integer)\nhead(demo.table)\n\n如果我们要取 PURCHASE UNEMPLOY PROF 三列中各自最大的 6 个值，可以使用如下方法\n\nlapply(demo.table[, c(\"PURCHASE\", \"FLOORSZ\", \"PROF\")], function (x) {\n    head(sort(x, decreasing = T))\n})\n\n可见 lapply 处理的是列表，返回的也是列表。可以使用 sapply 对输出结果进行自动简化，生成更易于观察的结果\n\nsapply(demo.table[, c(\"PURCHASE\", \"FLOORSZ\", \"PROF\")], function (x) {\n    head(sort(x, decreasing = T))\n})\n\n对于 vapply 这里就不再过多介绍了，其效果和 lapply 类似，只是接收一个向量。"
  },
  {
    "objectID": "02-数据预处理.html#空间数据操作",
    "href": "02-数据预处理.html#空间数据操作",
    "title": "2  数据预处理",
    "section": "2.3 空间数据操作",
    "text": "2.3 空间数据操作\n对于空间数据的操作，可以分成两类：\n\n对属性进行操作。这个操作方法和之前所讲的对表数据的操作方法相同，只是操作的对象是 @data 插槽中的值。\n对几何进行操作。这类操作有很多，相交、合并、投影……这里就不一一介绍。但这里主要讲一个操作——坐标系转换。\n\n\n2.3.1 坐标系转换\n坐标系转换，在 ArcGIS 中称作“投影”，就是把空间数据在一个坐标系下的坐标转换为另一种坐标系下的坐标。常用的有几种坐标：\n这一操作主要使用 rgdal 包中的 spTransform 进行实现。\n\nlibrary(rgdal)\n# 读取数据\ndemo.shp &lt;- readOGR(\"data/LNHP03.shp\")\nhead(demo.shp@coords)\n# 投影转换\ndemo.shp.wgs84 &lt;- spTransform(demo.shp, CRS(\"+proj=longlat +datum=WGS84 +no_defs\"))\nhead(demo.shp.wgs84@coords)\n\n该函数接收两个参数，第一个参数是要转换的 Spatial*DataFrame 数据；第二个参数是转换到的坐标系，是 CRS() 函数返回的对象。 函数 CRS() 接收一个 Proj4 格式的字符串，不同坐标系对应的 Proj4 字符串可在 EPSG 官网上进行查询。\n关于其他空间操作，详见《R 语言空间数据处理与分析实践教程》。"
  },
  {
    "objectID": "03-数据可视化.html#基本的可视化函数",
    "href": "03-数据可视化.html#基本的可视化函数",
    "title": "3  数据可视化",
    "section": "3.1 基本的可视化函数",
    "text": "3.1 基本的可视化函数\n\n3.1.1 绘图元素\n绘制图形，尤其是矢量图，是一个非常复杂的过程，需要有很多的配置设置。 但是有一些函数基本上包揽了这些工作，直接使用该函数，填写一些参数，就可以创建一个图表。 这些函数主要有：\n\nplot() 绘制散点图、折线图\nhist() 绘制直方图\n…\n\n最具代表性的就是用于绘制散点图的 plot() 函数。例如将 PURCHASE 和 FLOORSZ 的值绘制成散点图，可使用如下代码\n\nplot(demo.table$FLOORSZ, demo.table$PURCHASE, main = \"PURCHASE ~ FLOORSZ\", xlab = \"FLOORSZ\", ylab = \"PURCHASE\")\n\n\n\n\n甚至可以只对一个向量输出散点图\n\nplot(demo.table$PURCHASE, xlab = \"\", ylab = \"PURCHASE\")\n\n该函数具有很多配置参数，\n\n\n\n\n\n\n\n\n\n参数名\n类型\n含义\n默认值\n\n\n\n\nx y\nvector\n每个点的坐标\n\n\n\ntype\ncharacter\n输出图片的类型。p指散点图，l指折线图，b指同时输出点和线（不重叠），o指重叠输出点和线，h指以类似于直方图的形式输出。\n\"p\"\n\n\nxlim ylim\nvector\n\\(x\\) 轴和 \\(y\\) 轴的显示范围，分别是一个具有两个 numeric 类型元素的向量，前者作为下界，后者作为上界。\n\n\n\nlog\ncharacter\n指定哪些轴需要做对数变换。如果取值 \"x\" 或 \"y\" 则只在这些轴上变换，如果取值 \"xy\" 或 \"yx\" 则在两个轴上都做变换。\n\n\n\nmain sub\ncharacter\n图片主标题和副标题。一般传入一个字符串。\n\n\n\nxlab ylab\n\n\\(x\\) 轴和 \\(y\\) 轴的标题。一般传入一个字符串。\n\n\n\n…\n变长参数\n传给更底层绘图函数的参数。\n\n\n\n\n在该函数的基础上，可以增加一些辅助点、辅助线、文字等。分别使用 points() abline() grid() text() 等函数。\n\n# 辅助线\nplot(demo.table$PURCHASE)\nabline(h = 600000)\n\n\n# 背景格网、辅助线，文字\nplot(demo.table$FLOORSZ, demo.table$PURCHASE, xlim = c(0, 300), main = \"PURCHASE ~ FLOORSZ\", xlab = \"FLOORSZ\", ylab = \"PURCHASE\")\ngrid(nx = 20, ny = 20)   # x轴和 y轴格点的数量\nabline(a = 0, b = 1000)  # 斜率和截距\ntext(290, 320*1000, expression(\"£1000\"/m^2))  # 文字的横纵坐标以及内容\n\n\n\n3.1.2 颜色和形状\n以上这些函数中，绘图元素的颜色，都是通过 col 参数设置的。例如我们将上一个图中的辅助线改为红色\n\n# 背景格网、辅助线，文字\nplot(demo.table$FLOORSZ, demo.table$PURCHASE, xlim = c(0, 300), main = \"PURCHASE ~ FLOORSZ\", xlab = \"FLOORSZ\", ylab = \"PURCHASE\")\ngrid(nx = 20, ny = 20)   # x轴和 y轴格点的数量\nabline(a = 0, b = 1000, col = \"red\")  # 斜率和截距\ntext(290, 320*1000, expression(\"£1000\"/m^2), col = \"red\")  # 文字的横纵坐标以及内容\n\n颜色可以通过 colors() 函数查看内置的颜色，或者使用 rgb() hsv() hcl() 函数生成颜色值。这里不做过多介绍。\n点的形状是通过 pch 参数进行控制的，R 中一共包含 25 种点的样式，传入对应样式的序号即可。大小通过 cex 参数配置，接收一个浮点数，类似于放大缩小的比例，取值大于1则变大，小于1则变小。\n线的形状是通过 lty 参数进行控制的，R 种一共包含 6 种线的样式，传入对应样式的序号即可。线的粗细通过 lwd 参数配置，接收一个浮点数，可以理解为线纵向所占的像素数。\n字体的控制比较复杂，这里只介绍一下 family 参数，相当于在 Word 种所设置的字体，下面示例种填入的 \"serif\" 指默认的衬线字体，一般情况下系统会选择 Times New Roman 。当然这里也可以指定一些其他字体，但并不是所有字体都是 R 所支持的。\n\n# 背景格网、辅助线，文字\nplot(demo.table$FLOORSZ, demo.table$PURCHASE, xlim = c(0, 300), main = \"PURCHASE ~ FLOORSZ\", xlab = \"FLOORSZ\", ylab = \"PURCHASE\", pch = 3, cex = 0.8)\ngrid(nx = 20, ny = 20)   # x轴和 y轴格点的数量\nabline(a = 0, b = 1000, col = \"red\", lty = 2, lwd = 2, )  # 斜率和截距\ntext(300, 300*1000, expression(\"£1000\"/m^2), col = \"red\", family = \"serif\", cex = 1.5, adj = c(1, 0))  # 文字的横纵坐标以及内容\n\n有关这些绘图函数的详细情况，请查看《R 语言空间数据处理于分析实践教程》。"
  },
  {
    "objectID": "03-数据可视化.html#基础数据的可视化",
    "href": "03-数据可视化.html#基础数据的可视化",
    "title": "3  数据可视化",
    "section": "3.2 基础数据的可视化",
    "text": "3.2 基础数据的可视化\n用于数据可视化的包有很多，但是这里主要介绍使用 ggplot2 包进行可视化的方法。\n函数包 ggplot2 是由 Hadley Wickham 等人开发和维护的数据可视化工具函数包，是当前 R 中最流行的可视化函数包之一。 与大多数数据可视化函数包不同，函数包 ggplot2 基于 2005 年 Wilkinson 提出的图形语法开发，由一系列的独立可视化组件构成，这些组件可以被称为“图层”。 因此，ggplot2 的功能非常强大，可以根据不同的可视化问题与需求，量身定制不同的可视化图形。\n尽管 ggplot2 功能强大，但常用的可视化图无非是散点图、折线图、柱状图、饼图、直方图、箱线图等类型，而且理论上这些图都可以使用 plot 以及其他一些 R 自带的函数进行实现。 因此本节着重介绍这个包一些特有的功能，使用这些功能可以大大简化绘图流程。\n\nlibrary(ggplot2)\n\n\n3.2.1 散点图\n本节采用 iris 数据集进行演示。该数据集中包含了三种类型的鸢尾花的一些形态指标。\n\ndata(iris)\nhead(iris)\n\n我们使用这种方式展示字段 Sepal.Length 和 Sepal.Width 之间的关系，并给不同的鸢尾花类型使用不同的符号。\n\nggplot(iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species))  # 根据颜色区分鸢尾花\nggplot(iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width, shape = Species))  # 根据点形区分鸢尾花\n\n可见，ggplot 包首先要使用 ggplot() 函数创建一个绘图环境，然后在后面叠加所需要绘制的图层符号。\n上面所用到的 aes() 函数，是指定将数据映射到图层的参数， x y 表示点的坐标，此外 shape size color group 等绘图参数，分别将不同的数据映射到了不同的绘图元素上。 这个函数可以放在 gemo_points() 中，也可以放在 ggplot() 中。\n\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, group = Species, color = Species)) + geom_point()\n\n对于散点图，我们还可以添加一个回归曲线，使用 geom_smooth() 函数。如果 aes() 函数中对数据进行了分组，那么，geom_smooth() 就会对每个组分别进行回归。\n\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + geom_point() + geom_smooth(method = lm)\n\n我们也可以将其他两个参数加入，字段 Petal.Length 用大小表达，字段 Petal.Width 用颜色表达\n\nggplot(iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width, shape = Species, size = Petal.Length, color = Petal.Width))\n\n我们也可以更换一个比较学术化的主题，只需要在后面增加一个 theme_bw() 函数，即可进行主题设置\n\nggplot(iris) + \n    geom_point(aes(x = Sepal.Length, y = Sepal.Width, shape = Species)) + \n    theme_bw()\n\n\n\n3.2.2 折线图\n折线图一般用于表示一个变量随另一个变量的变化趋势，一般情况下这两个变量不会是一个类别变量，而且横轴的取值一般是连续型变量，或者是等差数列。\n这里使用 airquality 数据集，来展示对于时间序列的可视化。这个数据集中包含了纽约1973年5-9月每日空气质量。 我们需要用不同的线绘制出不同月份每天气温变化图。\n\nhead(airquality)\n\n\nggplot(airquality) +\n    geom_line(aes(x = Day, y = Temp, color = as.factor(Month)))\n\n这里使用到了一个 as.factor() 函数，根据这个名字，可以看到这个函数是将变量转换为 factor 类型的变量，这也是 R 中一个常用的数据类型——因子类型。 因子类型比较类似于实验中的控制变量，这种变量可以是整数，可以是字符串，但必须是有限个的，而且一般情况下每个因子有不同的重复实验。 这个案例中，月份就可以认为是因子。\n当然，折线图也不一定必须是时间序列的，例如下面这个数据集 CO2 描述了不同二氧化碳浓度下耐寒植物CO2摄取的差异。 我们可以分别画出不同植物在低温处理和非低温处理下吸收二氧化碳能力随二氧化碳浓度的变化图\n\nCO2.edit &lt;- CO2\nCO2.edit$Plant &lt;- sapply(CO2$Plant, FUN = function(x) {\n    paste(substring(x, 1, 1), substring(x, 3, 3), sep = \"\")\n})\nggplot(CO2.edit) +\n    geom_line(aes(x = conc, y = uptake, linetype = Treatment)) +\n    facet_wrap(~ Plant)\n\n上述代码中，使用 facet_wrap() 函数进行分幅绘图，接收一个 formula 对象，公式右边列出分组依据。还接受两个参数 nrow 和 ncol ，和创建矩阵时的用法一样。\n\n\n3.2.3 柱状图\n柱状图一般用于大小的比较，横轴上一般是一个类别变量，纵轴一般是一个整型变量或连续型变量。 如果已经统计好值，则使用 geom_col() 函数，如果需要 ggplot 进行统计，则使用 geom_bar() 函数。\n例如，我们统计三种鸢尾花品种花萼和花瓣的形态数据的平均值，使用柱状图进行展示。\n我们首先对该数据进行一个分组统计，统计出各组内指标的平均值。\n\nlibrary(dplyr)\niris.summary &lt;- data.frame(summarise(group_by(iris, Species), Sepal.Length.mean = mean(Sepal.Length), Sepal.Width.mean = mean(Sepal.Width)), row.names = \"Species\")\niris.summary\n\n其次注意到，这种形式的数据集，并不便于使用 ggplot 函数包进行可视化，因为数据映射中的 y 对应在了两列中。我们需要对其进行转换。\n\niris.summary.reshape &lt;- Reduce(rbind, lapply(rownames(iris.summary), FUN = function (x) {\n    data.frame(\n        Species = x,\n        Measurements = colnames(iris.summary),\n        Data = as.numeric(iris.summary[x,])\n    )\n}))\niris.summary.reshape\n\n\n这里使用到 Reduce(f, x) 函数，可以实现对 \\(x\\) 的第一、二两个元素运行函数 \\(f\\)，得到的结果与第三个元素再运行函数 \\(f\\)，以此类推，最后将 \\(x\\) 的所有元素整合到一起。 具体使用方法这里不做展开\n\n然后可以对 iris.reshape 进行可视化，使用两个柱子分别显示两组变量\n\nggplot(iris.summary.reshape) +\n    geom_col(aes(x = Species, y = Data, fill = Measurements), position = position_dodge2(padding = 0,  preserve = \"single\"))\n\n\n\n3.2.4 箱线图\n箱线图是将一组数据按照大小顺序排列后进行绘制的，包含6个数据节点，分别表示出数据的上边缘、上四分位数点Q3（数据从小到大排列后处在75％位置上的数据）、中位数、下四分位数Q1（数据从小到大排列后处在25％位置上的数据）、下边缘和异常值。由此，箱线图很形象地分为中心、延伸以及分布状态的全部范围。\n例如我们分析鸢尾花数据集中各个指标的分布，仍然需要先将数据集进行格式转换。\n\nmeasurements.colnames &lt;- colnames(iris)[-c(which(colnames(iris) == \"Species\"))]\niris.reshape &lt;- Reduce(rbind, (lapply(unique(iris$Species), FUN = function (x) {\n    item &lt;- filter(iris, Species == x)\n    Reduce(rbind, lapply(1:nrow(item), FUN = function (r) {\n        data.frame(\n            Species = x,\n            Measurements = measurements.colnames,\n            Data = as.numeric(item[r, measurements.colnames])\n        )\n    }))\n})))\nhead(iris.reshape)\n\n然后使用 gemo_boxplot() 函数绘制箱线图，\\(x\\) 轴设置为品种，\\(y\\) 轴设置为数值，然后根据指标进行分幅。\n\nggplot(iris.reshape) + geom_boxplot(aes(x = Species, y = Data, fill = Species)) + facet_wrap(~ Measurements)\n\n这样可以明显看出数据分布的方式。\n上面这个数据处理的方式是比较通用的，可以写成如下函数，方便以后使用。这个函数主要具有如下4个参数：\n\ndf 要处理的表数据\nfirst.names 数据处理的第一索引，将出现在结果的第一列中。\n\n如果是字符串，则取该字符串对应的列\n如果是字符串向量，则将该字符串向量作为第一索引\n如果是逻辑值，则将行名作为第一索引\n如果是数值，则将数值对应的列作为第一索引\n\ncol.names 要提取数据的列。如果为 NULL 则取除了 first.names 之外的所有列。这些列名的取值将出现在第二列。\noutput.names 输出数据的列名。\n\n如果不填，则程序自动处理列名。\n如果填一个，则第二列用该值，第一列用根据 first.names 提取的列名，第三列默认名称 Value\n如果填两个，则前两列使用该值，第三列默认名称 Value\n如果填三个，则三列全都使用该值\n\n\n\ndf.reshape.ggplot &lt;- function (df, first.names, col.names=NULL, output.names=c()) {\n    if (class(df) != \"data.frame\") {\n        stop(\"df must be a data.frame\")\n    }\n    first.index &lt;- c()\n    second.index &lt;- c()\n    use.first.name &lt;- \"primary.names\"\n    if (class(first.names) == \"character\" && length(first.names) == 1 && first.names %in% colnames(df)) {\n        first.index &lt;- df[[first.names]]\n        second.index &lt;- colnames(df)[-c(which(colnames(df) == first.names))]\n        use.first.name &lt;- first.names\n    } else if (length(first.names) == nrow(df)) {\n        first.index &lt;- first.names\n        second.index &lt;- colnames(df)\n    } else if (class(first.names) == \"logical\" && length(first.names) == 1 && first.names == TRUE) {\n        first.index &lt;- rownames(df)\n        second.index &lt;- colnames(df)\n    } else if (class(first.names) %in% c(\"numeric\", \"integer\") && length(first.names) == 1 && first.names == TRUE) {\n        first.names &lt;- as.integer(first.names)\n        first.index &lt;- df[, first.names]\n        second.index &lt;- colnames(df)[-c(first.names)]\n        use.first.name &lt;- colnames(df)[first.names]\n    } else {\n        stop(\"first.names accept a vector or a column name/index\")\n    }\n    df.reshape &lt;- Reduce(rbind, (lapply(unique(first.index), FUN = function (x) {\n        item &lt;- df[first.index == x,]\n        Reduce(rbind, lapply(1:nrow(item), FUN = function (r) {\n            data.frame(\n                \"primary.names\" = x,\n                \"secondary.names\" = as.character(second.index),\n                \"value\" = as.vector(as.matrix(item[r, second.index]))\n            )\n        }))\n    })))\n    if (length(output.names) == 0) {\n        colnames(df.reshape)[1] &lt;- use.first.name\n    } else if (class(output.names) == \"character\") {\n        if (length(output.names) == 3) {\n            colnames(df.reshape) &lt;- output.names\n        } else if (length(output.names) == 2) {\n            colnames(df.reshape)[1:2] &lt;- output.names\n        } else if (length(output.names) == 1) {\n            colnames(df.reshape)[1:2] &lt;- c(use.first.name, output.names)\n        } else {\n            warning(\"length of output.names is not between 1 and 3\")\n        }\n    }\n    df.reshape\n}\n\n\n\n3.2.5 直方图\n饼图主要展示各个值在不同区间内分布的频数，用于研究数据的概率分布。\n例如对鸢尾花数据集，我们可以分别查看三种花的 Sepal.Length 指标的分布情况。\n\nggplot(iris) + geom_histogram(aes(x = Sepal.Length), binwidth = 0.2) + facet_wrap(~ Species, ncol = 1)\n\n如果 aes() 中指定的是 y 则直方图变为横向，\n\nggplot(iris) + geom_histogram(aes(y = Sepal.Length), binwidth = 0.2) + facet_wrap(~ Species)"
  },
  {
    "objectID": "03-数据可视化.html#空间数据可视化",
    "href": "03-数据可视化.html#空间数据可视化",
    "title": "3  数据可视化",
    "section": "3.3 空间数据可视化",
    "text": "3.3 空间数据可视化\n空间数据可视化又称专题制图，即制作一个专题地图。专题地图就需要至少有四个要素：符号、图例、指北针、比例尺。这些可以通过程序自动添加。\n对于空间数据，其可视化有一个难点，即在二维地图上的 \\(x,y\\) 坐标已经被要素的空间位置所占据，只能通过颜色、大小、粗细来表示数值型变量的大小，通过形状等表示类别型变量的大小。 如果是三维地图，可以使用 \\(z\\) 轴来展示数值型变量的大小，也可以做出一些效果不错的专题图。但是三维可视化仍然存在很多问题，这里还是主要介绍二维可视化。\n我们以这个数据为例进行演示。\n\ndemo.shp &lt;- rgdal::readOGR(\"data/LNHP03.shp\")\n\n当加载了 sp 包之后，plot() 函数就可以直接绘制空间数据，用法如下\n\nlibrary(sp)\nplot(demo.shp)\n\n也可以显示空间面数据\n\ndata(LondonBorough, package = \"GWmodel\")\nplot(londonborough)\n\n二者也可以进行叠加显示\n\nplot(londonborough)\npoints(demo.shp)\n\n事实上， ggplot 包也可以做空间数据可视化，但是这里主要推荐使用 tmap 包，来提供更强大的可视化功能。\n\nlibrary(tmap)\n\n\n3.3.1 绘制符号\ntmap 包的使用思路是，使用 tm_shape() 添加一组要素，然后根据要素的类型，选择 tm_symbol() tm_polygon() 等函数进行可视化，\n将数据 demo.shp 使用点符号对变量 PURCHASE 进行可视化，给 col 参数传入一个列名，让函数根据该列的值进行可视化，用 size 参数传入点的大小。\n\ntm_shape(demo.shp) + tm_symbols(col = \"PURCHASE\", size = 0.2)\n\n如果我们不想要这么多分级，那么可以使用参数 n 对其进行设置\n\ntm_shape(demo.shp) + tm_symbols(col = \"PURCHASE\", size = 0.2, n = 3)\n\n我们也可以使用参数 palette 换一个配色方案\n\ntm_shape(demo.shp) + tm_symbols(col = \"PURCHASE\", size = 0.2, palette = \"Blues\")\n\n也可以同时可视化多组变量，并进行分幅输出\n\ntm_shape(demo.shp) + tm_symbols(col = c(\"PURCHASE\", \"FLOORSZ\", \"UNEMPLOY\", \"PROF\"), size = 0.2) + tm_facets()\n\n对于面要素，使用方法也是类似的，例如我们使用 World 数据集，来绘制全球人口分布图\n\ndata(World)\ntm_shape(World) + tm_polygons(\"life_exp\")\n\n我们也可以在一幅图上输出多个要素，这里使用 rivers 数据集，该数据集包括了全球的主要河流；以及 metro 数据，包含了多年全球各国人口。\n\ndata(rivers)\ntm_shape(World) + tm_polygons(col = \"white\") + tm_shape(rivers) + tm_lines(col = \"blue\")\n\n\ndata(metro)\ntm_shape(World) + tm_polygons(col = \"white\") + tm_shape(metro) + tm_symbols(size = \"pop2020\", col = \"\")\n\n\n\n3.3.2 指北针和比例尺\n指北针和比例尺的添加也是非常方便的，使用 tm_compass() 函数和 tm_scale_bar() 函数。\n\ntm_shape(demo.shp) + tm_symbols(col = \"PURCHASE\", size = 0.2) + tm_compass() + tm_scale_bar()\n\n图例是自动添加的，而指北针和比例尺的默认的位置是不太合适的。\n如果仅仅是调整位置，这两个函数都接收 position 参数，该参数接收一个二元向量，可以是字符串或 \\([0,1]\\) 区间内的数值。 如果是字符串，第一个值取 left``center``right 中的一个；第二个值取 top``center``bottom 中的一个。 可以是全小写，也可以是全大写。如果是全大写，则忽略边距。\n\ntm_shape(demo.shp) + tm_symbols(col = \"PURCHASE\", size = 0.2) + tm_compass(position = c(\"right\", \"top\")) + tm_scale_bar(position = c(\"left\", \"top\"))\n\n\n\n3.3.3 图名和图例\n图名和图例的添加和配置，和指北针、比例尺有些不同。图例是自动添加的，图名是需要指定的，他们都是在 tm_layout() 函数中进行设置的。\n\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\n\n第一个参数就是 title ，即图标题，其位置使用 main.position 参数进行设置。对于图例的位置，使用 legend.posistion 参数设置。\n该函数还有非常多的参数，这里难以一一介绍。可以使用下面这个方式，查看所有函数的帮助文档。对于 tm_layout() 函数，其参数默认值都还是比较合适的，一般就调整一下位置。"
  },
  {
    "objectID": "03-数据可视化.html#制图结果的输出",
    "href": "03-数据可视化.html#制图结果的输出",
    "title": "3  数据可视化",
    "section": "3.4 制图结果的输出",
    "text": "3.4 制图结果的输出\n制图结果我们需要输出到文件中，以在论文或其他文档中使用。 在 R 中输出图片的方式，是先创建一个绘图设备，然后使用语句进行绘图，最后关闭该设备，即可得到文件。 在 R 控制台中，默认的绘图设备是控制台的一个新窗口，在 Jupyter 中是一个 cell 的输出空间，在 RStudio 中是专门用于显示图片的子窗。\n创建绘图设备有几种类型，输出栅格图的 png jpg 等，输出矢量图的 eps pdf 等。在 Windows 上，还有 emf 这种设备，可以直接嵌入到 Office 中。\n关闭绘图设备的函数是 dev.off()。\n\n3.4.1 位图输出\n这里以 png 为例展示输出位图图片的方式。\n\npng(filename = \"output-03/PURCHASE.png\", width = 1024, height = 1024, units = \"px\", res = 300, pointsize = 12)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\n\n该函数中有以下几个参数：\n\nwidth height 是设置图片宽高的，参数 units 是指宽高设置数值的单位。\nunits 可以取 px 表示像素，也可以取 cm in 表示长度。而不同单位的设置方法，也会影响 res 的效果。\nres 是指 PPI（Pixel Per Inch） ，即图像的采样率（在图像中，每英寸所包含的像素数目）\npointsize 是绘图点大小，单位是 \\(1/72\\)。\n\n关于这些参数的设置，我们可以对比以下几张图。\n\npng(filename = \"output-03/PURCHASE-2400px-300dpi-12.png\", width = 2400, height = 2400, units = \"px\", res = 300)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-1200px-300dpi-12.png\", width = 1200, height = 1200, units = \"px\", res = 300)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-1200px-72dpi-12.png\", width = 1200, height = 1200, units = \"px\", res = 72)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-1200px-72dpi-6.png\", width = 1200, height = 1200, units = \"px\", res = 72, point = 6)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-1200px-72dpi-18.png\", width = 1200, height = 1200, units = \"px\", res = 72, point = 18)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-8in-300dpi-12.png\", width = 8, height = 8, units = \"in\", res = 300)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-4in-300dpi-12.png\", width = 4, height = 4, units = \"in\", res = 300)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-4in-72dpi-12.png\", width = 4, height = 4, units = \"in\", res = 72)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-4in-72dpi-6.png\", width = 4, height = 4, units = \"in\", res = 72, point = 6)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\npng(filename = \"output-03/PURCHASE-4in-72dpi-18.png\", width = 4, height = 4, units = \"in\", res = 72, point = 18)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\n\n可以看到，图片尺寸 \\(l\\)、PPI \\(p\\)、点大小 \\(s\\) 都对生成的图片有影响。我们分别对 units 是物理长度和像素两种情况进行分析。\n由于 R 中所绘制的图都是矢量图，就像在一张 A4 纸上绘制函数图像一样。 例如，当我们需要在图上绘制 \\((2,2)\\) 这个点时，如何确定这个点应该画在哪里？ 我们首先假定以 A4 纸的左下角为原点，沿纸边缘为坐标轴，1 cm 为单位长度。那么 \\((2,2)\\) 就绘制在了距离原点 (2 cm, 2 cm) 的位置。 那如果我们规定 2 cm 为单位长度，这个点就会被绘制到 (4 cm, 4 cm) 的位置。 但是，实际上，为了让绘图内容以最大化的方式占满绘图空间，单位长度是根据绘制内容进行确定的，而且两个方向上的单位长度不一定一样。\n那如果我们有一个长 10 宽 10 的正方形，想要最大化绘制在 A4 纸上，并且要在外面留下一定长度的边距，那么就需要计算一下这个正方形的各个格点的坐标。 此时如果其他要求不变，要把这个正方形绘制到一张 A2 纸（A4纸的四倍）上，此时最然正方形的长宽还是 10 单位长度，但是一个单位长度的实际物理长度就变大了。 那么如果这个正方形内部有 64 个等间距的格点，相比在 A4 纸上绘制，这 64 个格点之间的间距就要大很多。 这就是输出图片尺寸 \\(l\\) 的影响。\n但是实际上，无论是打印机、绘图仪还是纸笔，在绘图的时候，都是以一个很小的正方形代替一个数学意义上的点，这个点可以大可以小，类似于圆珠笔和记号笔的笔画差异。 当我们用圆珠笔画点的时候，画出来的点在物理尺寸上比较小，但是用记号笔时，画出来的点物理尺寸就比较大。 虽然这些点中心的位置是相同的，但是点的尺寸是不相同的。 使用粗的笔时，如果要让看起来形状和细的笔形状差不多，那这个符号就要画的大一些。 这就是输出点大小 \\(s\\) 的影响。\n那么现在如果我们把这张纸扫描成图片，那么这个扫描仪每个像素的尺寸就决定了图片的清晰度。 如果这个扫描仪每英寸有 72 个像素（72 PPI），其输出图片的尺寸就会比每英寸有 300 个像素的扫描仪小很多。 如果我们都是用 300 PPI 的扫描仪，扫描 A2 纸得到的图像大小就会是扫描 A4 纸得到的图像大小的 4 倍。 这就是 PPI \\(p\\) 的影响。\n所以，如果我们把 units 设置为物理长度，生成的位图的像素数就是宽高 \\((w,h)\\) 与 PPI 的乘积，字体、符号的大小通过点大小 \\(s\\) 控制。\n当 units 是像素时，程序需要保证输出的图片像素数是固定的，此时程序需要根据输出像素数和 PPI 来确定绘图区域的物理尺寸，进一步确定绘图单位长度。 例如，如果指定图片宽和高的像素数是 1200 px ，输出 PPI 是 300 ，那么绘图区域的物理尺寸就是 4 in。 如果指定图片宽和高的像素数改为是 2400 px，那么物理尺寸就是 8 in。 如果指定图片宽和高的像素数是 1200 px，把输出 PPI 改为 72，则绘图区域物理尺寸就是 \\(16\\frac{2}{3}\\) in。 剩下的就之前的过程没有区别了。\n\n需要指出的是，当图片放在电脑中时，是没有 DPI 的概念的。DPI 是指每英寸点数，当图片还是电脑中的文件时，只存在像素数，不存在物理尺寸。 只有当图片打印到纸上，或者显示到显示器上，此时图片被绘制出来，具有了物理尺寸，才涉及到 DPI 。 总的来说，同样一张图片，第一次打印出来占满一张 A4 纸，第二次打印出来占四分之一张 A4 纸，那么可以说第二次的 DPI 是第一次的两倍。 很多期刊投稿时对 DPI 有要求，而且不同类型的图片要求不同，在输出图片的时候， res 参数的值需要灵活设置。 即使设置了 res 参数为 300 ，但如果图片尺寸过小，排版时被放大，就依然有可能达不到印刷要求。 最保险的办法是直接根据纸张最大的尺寸绘制图片，选择最大的 PPI ，当然这就会大大增加图片的大小。 如果图片太多，导致超出了投稿文件容量上限，此时就需要根据图片实际排版，确定合适的尺寸。 因此，建议 units 参数传入物理长度，而不建议使用像素数。\n\n对于 tmap 包绘制的图，该包提供了一个函数 tmap_save() 来保存图片。 该函数第一个参数接收 tmap 相关绘图函数的返回值，参数 filename 为输出文件名，width``height``units 与 png 函数相同，dpi 与 res 对应，此外还有一些其他设置参数。\n\nm &lt;- tm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ntmap_save(m, filename = \"output-03/PURCHASE_tmap.png\", width = 8, height = 8, units = \"in\", dpi = 300)\n\n\n\n3.4.2 矢量图输出\n对于矢量图来说，其格式非常的多，而且不同系统的支持也不一样。 在 Office 系列软件中，使用的 emf 格式的矢量图。在 LaTeX 等软件中，支持 eps 格式的矢量图。 虽然 PDF 格式是基本通用的，在任何系统上都能打开，但是也不能嵌入到 Word 中。 而 SVG 格式可以嵌入到 Word 中，基本也可以在各个系统上打开。但是其对于中文的处理还有一定的问题。\n这里以生成 PDF 格式和 SVG 格式的图片为例，演示如何输出矢量图。\n\npdf(file = \"output-03/PURCHASE.pdf\", width = 8, height = 8, pointsize = 12)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\n\n\nsvg(file = \"output-03/PURCHASE.svg\", width = 8, height = 8, pointsize = 12)\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()\n\n可以发现，对于矢量图，只需要设置宽高和点大小即可，使用起来还是比较方便的。当然还有很多其他参数，例如字体的设置等，这里就不一一介绍了，只演示一下如何输出衬线字体的图片。\n\nsvg(file = \"output-03/PURCHASE_serif.svg\", width = 8, height = 8, pointsize = 12, family = \"serif\")\ntm_shape(demo.shp) + \n    tm_symbols(col = \"PURCHASE\", size = 0.2) + \n    tm_compass(position = c(\"right\", \"top\")) + \n    tm_scale_bar(position = c(\"right\", \"bottom\")) +\n    tm_layout(\"Map of Housing Price\", main.title.position = c(\"left\", \"top\"), legend.position = c(\"left\", \"bottom\"))\ndev.off()"
  },
  {
    "objectID": "04-数据分析.html#相关分析",
    "href": "04-数据分析.html#相关分析",
    "title": "4  数据分析",
    "section": "4.1 相关分析",
    "text": "4.1 相关分析\n相关分析是分析变量之间的相关性，从而为回归分析的变量选择提供依据。 进行相关分析的包有很多，这里主要介绍 PerformanceAnalytics 的 chart.Correlation() 函数。该函数的特点是提供的信息比较多，有散点图、直方图、相关系数值等，而且相关系数值的字体大小会随着相关系数的大小而变化。\n\nPerformanceAnalytics::chart.Correlation(londonhp@data[, c(\"PURCHASE\", \"BATH2\", \"FLOORSZ\", \"PROF\", \"UNEMPLOY\")], histogram = T)\n\n由此我们可以看到，PURCHASE 变量和 BATH2 FLOORSZ PROF 三个变量相关性比较强。\n该函数默认使用皮尔逊相关系数，如果像计算斯皮尔曼相关系数，则使用 method 参数进行指定。\n\nPerformanceAnalytics::chart.Correlation(londonhp@data[, c(\"PURCHASE\", \"BATH2\", \"FLOORSZ\", \"PROF\", \"UNEMPLOY\")], histogram = T, method = \"spearman\")"
  },
  {
    "objectID": "04-数据分析.html#空间相关分析",
    "href": "04-数据分析.html#空间相关分析",
    "title": "4  数据分析",
    "section": "4.2 空间相关分析",
    "text": "4.2 空间相关分析\n空间相关分析，主要根据全局莫兰指数和局部莫兰指数进行分析。主要用到的函数包为 spdep 包。\n\nlibrary(spdep)\n\n\n4.2.1 全局空间自相关\n莫兰指数的定义如下：\\[ I = \\frac{n}{\\sum_i \\sum_j w_{ij}} \\frac{ \\sum_i \\sum_j w_{ij} (z_i - \\bar{z})(z_j - \\bar{z}) }{ \\sum_i (z_i - \\bar{z})^2 } \\] 其中 \\(w\\) 为根据空间邻域计算的权重矩阵。\n在 R 中，该值的计算方法是\n\nlondonhp.nb &lt;- knn2nb(knearneigh(londonhp, k = 4, longlat = F))\nlondonhp.nb.s &lt;- make.sym.nb(londonhp.nb)\nmoran.test(londonhp$PURCHASE, listw = nb2listw(londonhp.nb.s))\n\n\n中间涉及到 knn2nb knearneigh make.sym.nb nb2listw 几个函数，都是用来生成空间邻域权重矩阵的，具体含义和使用方法请查看帮助文档。\n\n在结果中可以看到，莫兰指数 \\(I\\) 的 \\(p\\) 值很小，表示数据中含有自相关性；否则即使 \\(I\\) 不是 0，也不能认为有相关性。 然后根据莫兰指数 \\(I\\) 的值，判断相关性的类型：\n\n\\(I &gt; 0\\) 表示正相关\n\\(I &lt; 0\\) 表示负相关\n\n除了莫兰指数以外，还有 Geary 系数也比较常用，该系数的用法请参考《R 语言空间统计与分析实践教程》。\n\n\n4.2.2 局部空间自相关\n局部空间自相关使用局部莫兰指数，其定义如下 \\[ I_i = \\frac{n}{\\sum_j w_{ij}} \\frac{ \\sum_j w_{ij} (z_i - \\bar{z})(z_j - \\bar{z}) }{ \\sum_k (z_k - \\bar{z})^2 } \\] 其中 \\(w\\) 为根据空间邻域计算的权重矩阵。\n在 R 中使用 localmoran() 函数进行计算，\n\nlondonhp.localmoran.PURCHASE &lt;- localmoran(londonhp$PURCHASE, listw = nb2listw(londonhp.nb.s, style = \"W\"))\nhead(londonhp.localmoran.PURCHASE)\n\n下面我们可以将其在地图上进行可视化，来观察变量的局部相关性分布情况。\n\nlondonhp.localmoran.PURCHASE.sdf &lt;- data.frame(londonhp@coords, londonhp.localmoran.PURCHASE)\ncoordinates(londonhp.localmoran.PURCHASE.sdf) &lt;- ~ coords.x1 + coords.x2\nproj4string(londonhp.localmoran.PURCHASE.sdf) &lt;- proj4string(londonhp)\ntm_shape(londonborough) + tm_polygons(col = \"white\") + tm_shape(londonhp.localmoran.PURCHASE.sdf) + tm_symbols(col = \"Ii\", size = 0.2)\n\n函数 moran.plot 用于辅助查看空间自相关特征，使用方法如下\n\nmoran.plot(londonhp$PURCHASE, nb2listw(londonhp.nb.s, style = \"W\"), pch = 19)\n\n根据点集落入的象限，可以分析空间自相关特征。"
  },
  {
    "objectID": "04-数据分析.html#地理加权分析",
    "href": "04-数据分析.html#地理加权分析",
    "title": "4  数据分析",
    "section": "4.3 地理加权分析",
    "text": "4.3 地理加权分析\n地理加权分析，其方法主要由 GWmodel 包提供，包括地理加权汇总统计分析（GWSS）、地理加权回归分析（GWR）、地理加权主成分分析（GWPCA）、地理加权判别分析（GWDA）等。 不同地分析方法分别有不同的作用，需要搭配使用。\n\nlibrary(GWmodel)\n\nLoading required package: maptools\n\nChecking rgeos availability: TRUE\n\nLoading required package: robustbase\n\nLoading required package: Rcpp\n\nLoading required package: spatialreg\n\nLoading required package: spData\n\nTo access larger datasets in this package, install the spDataLarge\npackage with: `install.packages('spDataLarge',\nrepos='https://nowosad.github.io/drat/', type='source')`\n\nLoading required package: Matrix\n\nRegistered S3 methods overwritten by 'spatialreg':\n  method                   from \n  residuals.stsls          spdep\n  deviance.stsls           spdep\n  coef.stsls               spdep\n  print.stsls              spdep\n  summary.stsls            spdep\n  print.summary.stsls      spdep\n  residuals.gmsar          spdep\n  deviance.gmsar           spdep\n  coef.gmsar               spdep\n  fitted.gmsar             spdep\n  print.gmsar              spdep\n  summary.gmsar            spdep\n  print.summary.gmsar      spdep\n  print.lagmess            spdep\n  summary.lagmess          spdep\n  print.summary.lagmess    spdep\n  residuals.lagmess        spdep\n  deviance.lagmess         spdep\n  coef.lagmess             spdep\n  fitted.lagmess           spdep\n  logLik.lagmess           spdep\n  fitted.SFResult          spdep\n  print.SFResult           spdep\n  fitted.ME_res            spdep\n  print.ME_res             spdep\n  print.lagImpact          spdep\n  plot.lagImpact           spdep\n  summary.lagImpact        spdep\n  HPDinterval.lagImpact    spdep\n  print.summary.lagImpact  spdep\n  print.sarlm              spdep\n  summary.sarlm            spdep\n  residuals.sarlm          spdep\n  deviance.sarlm           spdep\n  coef.sarlm               spdep\n  vcov.sarlm               spdep\n  fitted.sarlm             spdep\n  logLik.sarlm             spdep\n  anova.sarlm              spdep\n  predict.sarlm            spdep\n  print.summary.sarlm      spdep\n  print.sarlm.pred         spdep\n  as.data.frame.sarlm.pred spdep\n  residuals.spautolm       spdep\n  deviance.spautolm        spdep\n  coef.spautolm            spdep\n  fitted.spautolm          spdep\n  print.spautolm           spdep\n  summary.spautolm         spdep\n  logLik.spautolm          spdep\n  print.summary.spautolm   spdep\n  print.WXImpact           spdep\n  summary.WXImpact         spdep\n  print.summary.WXImpact   spdep\n  predict.SLX              spdep\n\nWelcome to GWmodel version 2.2-2.\nThe new version of GWmodel 2.2-2 now is ready\n\n\n\n\n4.3.1 GWR\n地理加权回归分析是考虑空间异质性的回归方法，其回归方程是 \\[ y_i = \\beta_{i0} + \\sum_{k=1}^{K}\\beta_{ik}x_{ik} + \\epsilon_i \\] 其中 $ y_i $ 是在位置 \\(i\\) 处的因变量； $ x_{ik} $ 是位置 \\(i\\) 上第 \\(k\\) 个自变量; $ K $ 自变量总数；$ _{i0} $ 是位置 \\(i\\) 上的截距；\\(\\beta_{ik}\\) 位置 \\(i\\) 上第 \\(k\\) 个自变量的回归系数；$ _i $ 是位置 \\(i\\) 上的随机误差，服从正态分布。\n其解算方法是加权最小二乘，即 \\[ \\hat{\\beta}_i = \\left( X^T W_i X \\right)^{-1} \\left( X^T W_i y \\right) \\] 其中 \\(w_{ij}\\) 通过核函数和回归点 \\(i,j\\) 之间的距离计算。距离一般是欧氏距离，或者路网距离、通勤时间等。核函数主要有以下几种：\n\ngaussian 非截断型带宽 \\[w_{ij} = \\exp\\left[-\\frac{1}{2}\\left( \\frac{d_{ij}}{b} \\right)^2 \\right]\\]\nbisquare 截断型带宽: \\[w_{ij} = \\left\\{ \\begin{array}{ll} \\left(1 - \\frac{d_{ij}^2}{b^2} \\right)^2, & \\mathrm{if} d_{ij} \\leq b \\\\ 0, & \\mathrm{otherwise} \\end{array}  \\right.\\]\ntriqurbe 截断型带宽: \\[w_{ij} = \\left\\{ \\begin{array}{ll} \\left(1 - \\frac{d_{ij}^2}{b^3} \\right)^3, & \\mathrm{if} d_{ij} \\leq b \\\\ 0, & \\mathrm{otherwise} \\end{array}  \\right.\\]\n\n进行 GWR 分析的方法主要有三步：模型优选、带宽优选、模型拟合。前两步主要是用于选择一个最优参数，其结果是参考性的。\n\n4.3.1.1 模型优选\n使用 gwr.model.selection() 函数进行模型优选，该函数需要指定因变量和自变量。\n\nlondonhp.indep.vars &lt;- colnames(londonhp@data)[-1]\nlondonhp.depen.vars &lt;- colnames(londonhp@data)[1]\nlondonhp.model.sel &lt;- gwr.model.selection(DeVar = londonhp.depen.vars, InDeVars = londonhp.indep.vars, data = londonhp, \n                                          bw = Inf, adaptive = T, kernel = \"gaussian\", longlat = F,\n                                          parallel.method = \"omp\", parallel.arg = 8)\nlondonhp.model.sort &lt;- gwr.model.sort(londonhp.model.sel, length(londonhp.indep.vars), londonhp.model.sel[[2]][,2])\n\n然后根据下面三张图，可以分析究竟应该选择哪个模型\n\n## 模型列表\ngwr.model.view(DeVar = londonhp.depen.vars, InDeVars = londonhp.indep.vars, londonhp.model.sort[[1]])\n## 模型 AIC 值\nlondonhp.model.ruler &lt;- londonhp.model.sort[[2]][,2]\nplot(londonhp.model.ruler, type = \"b\", pch = 20, lty = 2)\n## 模型 AIC 变化\nlondonhp.model.ruler.diff &lt;- c(0, diff(londonhp.model.ruler))\nplot(londonhp.model.ruler.diff, ylim = c(-50, 0))\nabline(h = -3)\ntext(x = 1:length(londonhp.model.ruler.diff), y = londonhp.model.ruler.diff, labels = as.character(1:length(londonhp.model.ruler.diff)))\n\n可以看到，第 115 个模型是比较好的模型。下面有两种方法获取该模型，一种是根据第一张图查找 115 号模型的自变量。 另一种方法是，直接根据输出结果获取表达式。\n\nlondonhp.model.best &lt;- londonhp.model.sort[[1]][[115]]\nlondonhp.model.formula &lt;- formula(londonhp.model.best[[1]])\nlondonhp.model.indep &lt;- londonhp.model.best[[2]]\nlondonhp.model.formula\n\n\n\n4.3.1.2 带宽优选\n在选好了模型的基础上，使用 bw.gwr() 函数进行带宽优选。\n\nlondonhp.bw &lt;- bw.gwr(londonhp.model.formula, londonhp,\n                      kernel = \"gaussian\", adaptive = T, longlat = F,\n                      parallel.method = \"omp\", parallel.arg = 8)\n\n返回的 londonhp.bw 即是最优带宽值。\n\n\n4.3.1.3 模型解算\n在选好模型和带宽的基础上，使用 gwr.basic() 函数解算模型。\n\nlondonhp.model.gwr &lt;- gwr.basic(londonhp.model.formula, londonhp,\n                                bw = londonhp.bw, kernel = \"gaussian\", adaptive = T, longlat = F,\n                                parallel.method = \"omp\", parallel.arg = 8)\nlondonhp.model.gwr\n\n返回结果 londonhp.model.gwr 是一个列表，最重要的是以下两个键值对：\n\nSDF 是一个 Spatial*DatFrame, 和原始数据的类型一致，包含每个点上的回归系数和截距，以及一些其他信息。\ndiagnostic 诊断信息，包含 AIC, \\(R^2\\) 值等，在上述结果输出中也可以看到。\n\n我们可以先将 SDF 的值的列名进行输出\n\ncolnames(londonhp.model.gwr$SDF@data)\n\n可见，该变量包含以下列：\n\n前 \\(k\\) 列（\\(k\\) 是自变量数+1）是每个要素的回归系数\n后面跟着真值 \\(y\\)，估计值 \\(\\hat{y}\\)，残差值 \\(\\epsilon\\)， CV 值和学生残差值\n后面跟着 \\(k\\) 个回归系数（包括截距）的标准差\n后面跟着 \\(k\\) 个回归系数（包括截距）的 t 检验值\n最后一列是局部 \\(R^2\\) 值\n\n我们可以对这些系数进行可视化输出\n\ntm_shape(londonhp.model.gwr$SDF) + tm_symbols(col = \"Intercept\", size = 0.2)\n\n下面我们使用数据集 LondonBorough 制作完整的专题图。\n\ntm_shape(londonborough) + tm_polygons(col = \"white\") + tm_shape(londonhp.model.gwr$SDF) + tm_symbols(col = \"Intercept\", size = 0.2)\n\n\n\n\n4.3.2 GWSS\nGWSS 包含以下几类地理加权汇总统计量：\n\n局部平均数 \\[ \\bar{x}(u_i,v_i) = \\frac{\\sum_j x_j w_{ij}}{\\sum_j w_{ij}} \\]\n局部标准差 \\[ SD(u_i,v_i) = \\frac{\\sqrt{\\sum_j (x_j - \\bar{x}(u,v))^2 w_{ij}}}{\\sum_j w_{ij}} \\]\n局部方差 \\[ Var(u_i,v_i) = \\frac{{\\sum_j (x_j - \\bar{x}(u,v))^2 w_{ij}}}{\\sum_j w_{ij}} \\]\n局部偏度\n局部变异系数\n局部协方差 \\[ Cov_{x,y}(u_i,v_i) = \\frac{{\\sum_j  w_{ij} (x_j - \\bar{x}_i(u_i,v_i)) (y_j - \\bar{y}_i)(u_i,v_i)}}{\\sum_j w_{ij}} \\]\n局部皮尔逊相关系数 \\[ Corr_{x,y}(u_i,v_i) = \\frac{ Cov_{x,y}(u_i,v_i) }{ SD_x(u_i,v_i) \\times SD_y(u_i,v_i) } \\]\n局部斯皮尔曼相关系数\n\n函数 gwss() 提供该功能。GWSS 的使用没有像 GWR 那么复杂，只是计算几个统计量。使用方法如下\n\nlondonhp.gwss &lt;- gwss(londonhp, vars = c(\"PURCHASE\", \"FLOORSZ\", \"PROF\", \"UNEMPLOY\"), \n                      kernel = \"gaussian\", adaptive = TRUE, bw = 100, longlat = F)\nlondonhp.gwss\n\n同样，变量 londonhp.gwss 是一个列表，其中有一个 SDF 的键值对，包含了每个要素上 GWSS 统计量的计算结果。\n\ncolnames(londonhp.gwss$SDF@data)\n\n我们也可以将其进行可视化\n\ntm_shape(londonborough) + tm_polygons(col = \"white\") + tm_shape(londonhp.gwss$SDF) + tm_symbols(col = \"PURCHASE_LM\", size = 0.2)\ntm_shape(londonborough) + tm_polygons(col = \"white\") + tm_shape(londonhp.gwss$SDF) + tm_symbols(col = \"Corr_PURCHASE.PROF\", size = 0.2)\n\n\n\n4.3.3 GWPCA\nGWPCA 是一种局部加权的 PCA 算法，用于分析局部尺度下主成分的不同。\n在进行主成分分析之前，我们需要对数据进行归一化处理，处理的方法是 \\[ \\tilde{x}_i = \\frac{x_i - \\bar{x}}{\\mathrm{Var}(x)} \\] 在 R 中，使用 scale 函数即可\n\nlondonhp.scaled &lt;- londonhp\nlondonhp.scaled@data &lt;- as.data.frame(scale(as.matrix(londonhp@data[,c(\"FLOORSZ\", \"PROF\", \"UNEMPLOY\")])))\n\n使用 gwpca() 函数进行 GWPCA 解算。\n\nlondonhp.gwpca &lt;- gwpca(londonhp.scaled, vars = c(\"FLOORSZ\", \"PROF\", \"UNEMPLOY\"), k = 2,\n                        kernel = \"gaussian\", adaptive = TRUE, bw = 100, longlat = F)\nlondonhp.gwpca\n\nWarning message in proj4string(data):\n“CRS object has comment, which is lost in output”\nWarning message in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj = prefer_proj):\n“Discarded datum Unknown based on Airy 1830 ellipsoid in CRS definition”\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2021-01-14 10:58:44 \n   Call:\n   \n   Variables concerned:  FLOORSZ PROF UNEMPLOY\n   The number of retained components:  2\n   Number of data points: 2108\n   ***********************************************************************\n   *                Results of Principal Components Analysis               *\n   ***********************************************************************\nImportance of components:\n                          Comp.1    Comp.2    Comp.3\nStandard deviation     1.2425881 0.9934353 0.6848803\nProportion of Variance 0.5146751 0.3289713 0.1563537\nCumulative Proportion  0.5146751 0.8436463 1.0000000\n\nLoadings:\n         Comp.1 Comp.2 Comp.3\nFLOORSZ   0.184  0.977  0.105\nPROF      0.688 -0.205  0.696\nUNEMPLOY -0.702  0.055  0.710\n\n   ***********************************************************************\n   *   Results of Geographically Weighted Principal Components Analysis  *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function for geographically weighting: gaussian \n   Adaptive bandwidth for geographically and temporally  weighting: 100 (number of nearest neighbours)\n   Distance metric for geographically weighting: A distance matrix is specified for this model calibration.\n\n   ****************     Summary of GWPCA information:    *****************\n   Local variance: \n             Min. 1st Qu.  Median 3rd Qu.   Max.\n   Comp.1 0.44818 0.73382 0.91733 1.11706 2.2363\n   Comp.2 0.30006 0.49736 0.59489 0.72957 1.1960\n   Local Proportion of Variance: \n                Min. 1st Qu. Median 3rd Qu.   Max.\n   Comp.1     43.185  51.370 54.606  57.378 64.453\n   Comp.2     27.245  33.347 35.127  37.705 44.821\n   Cumulative 85.087  88.288 89.655  91.399 95.067\n\n   ***********************************************************************\n   Program stops at: 2021-01-14 10:58:57 \n\n\n返回值 londonhp.gwpca 也是一个列表，主要有以下几个键值对：\n\nSDF : 存储各个要素上的 GWPCA 分析的结果，包含前 k 个主成分的值 Comp.1_PV Comp.2_PV … Comp.$k$_PV，累积占比 local_CP，以及优胜变量 win_var_PC1 。\nloadings : 各个要素上的载荷矩阵\ngwpca.scores : 各个要素上的得分值（只有设置了 score 参数才有值）\nlocal.PV : 各个要素上的特征值\n\n我们可以将优胜变量进行可视化\n\ntm_shape(londonborough) + tm_polygons(col = \"white\") + tm_shape(londonhp.gwpca$SDF) + tm_symbols(col = \"win_var_PC1\", size = 0.2)\n\nWarning message in sp::proj4string(obj):\n“CRS object has comment, which is lost in output”\n\n\n\n\n\n也可以对载荷矩阵进行可视化，以分析其空间异质性。 该可视化方法在 tmap 包中没有，因此需要使用 GWmodel 包中的一个函数绘制，而此时就不能使用 tmap 来显示底图，需要使用 plot() 函数来显示底图。\n\nlondonhp.loadings &lt;- londonhp.gwpca$loadings[,,1]\nplot(londonborough, asp = 1, xaxt = \"n\", yaxt = \"n\", xlab = \"\", ylab = \"\", bty = \"n\", col = \"white\")\nglyph.plot(londonhp.loadings, londonhp.gwpca$SDF@coords, add = TRUE)\n\n\n\n\n\nplot(bss.background, asp = 1, type = \"l\", xaxt = \"n\", yaxt = \"n\", \n   xlab = \"\", ylab = \"\", bty = \"n\", col = \"grey\")"
  }
]